{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import certifi\n",
    "import os\n",
    "import ssl\n",
    "\n",
    "# SSL 인증서 설정\n",
    "os.environ['SSL_CERT_FILE'] = certifi.where()\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "class Img2Vec():\n",
    "    RESNET_OUTPUT_SIZES = {\n",
    "        'resnet18': 512,\n",
    "        'resnet34': 512,\n",
    "        'resnet50': 2048,\n",
    "        'resnet101': 2048,\n",
    "        'resnet152': 2048\n",
    "    }\n",
    "\n",
    "    EFFICIENTNET_OUTPUT_SIZES = {\n",
    "        'efficientnet_b0': 1280,\n",
    "        'efficientnet_b1': 1280,\n",
    "        'efficientnet_b2': 1408,\n",
    "        'efficientnet_b3': 1536,\n",
    "        'efficientnet_b4': 1792,\n",
    "        'efficientnet_b5': 2048,\n",
    "        'efficientnet_b6': 2304,\n",
    "        'efficientnet_b7': 2560\n",
    "    }\n",
    "\n",
    "    def __init__(self, cuda=False, model='resnet18', layer='default', layer_output_size=512, gpu=0):\n",
    "        self.device = torch.device(f\"cuda:{gpu}\" if cuda else \"cpu\")\n",
    "        self.layer_output_size = layer_output_size\n",
    "        self.model_name = model\n",
    "\n",
    "        self.model, self.extraction_layer = self._get_model_and_layer(model, layer)\n",
    "\n",
    "        self.model = self.model.to(self.device)\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "        self.scaler = transforms.Resize((224, 224))\n",
    "        self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                              std=[0.229, 0.224, 0.225])\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "\n",
    "    def get_vec(self, img, tensor=False):\n",
    "        if type(img) == list:\n",
    "            a = [self.normalize(self.to_tensor(self.scaler(im))) for im in img]\n",
    "            images = torch.stack(a).to(self.device)\n",
    "            if self.model_name in ['alexnet', 'vgg']:\n",
    "                my_embedding = torch.zeros(len(img), self.layer_output_size)\n",
    "            elif self.model_name == 'densenet' or 'efficientnet' in self.model_name:\n",
    "                my_embedding = torch.zeros(len(img), self.layer_output_size, 7, 7)\n",
    "            else:\n",
    "                my_embedding = torch.zeros(len(img), self.layer_output_size, 1, 1)\n",
    "\n",
    "            def copy_data(m, i, o):\n",
    "                my_embedding.copy_(o.data)\n",
    "\n",
    "            h = self.extraction_layer.register_forward_hook(copy_data)\n",
    "            with torch.no_grad():\n",
    "                h_x = self.model(images)\n",
    "            h.remove()\n",
    "\n",
    "            if tensor:\n",
    "                return my_embedding\n",
    "            else:\n",
    "                if self.model_name in ['alexnet', 'vgg']:\n",
    "                    return my_embedding.numpy()[:, :]\n",
    "                elif self.model_name == 'densenet' or 'efficientnet' in self.model_name:\n",
    "                    return torch.mean(my_embedding, (2, 3), True).numpy()[:, :, 0, 0]\n",
    "                else:\n",
    "                    return my_embedding.numpy()[:, :, 0, 0]\n",
    "        else:\n",
    "            image = self.normalize(self.to_tensor(self.scaler(img))).unsqueeze(0).to(self.device)\n",
    "\n",
    "            if self.model_name in ['alexnet', 'vgg']:\n",
    "                my_embedding = torch.zeros(1, self.layer_output_size)\n",
    "            elif self.model_name == 'densenet' or 'efficientnet' in self.model_name:\n",
    "                my_embedding = torch.zeros(1, self.layer_output_size, 7, 7)\n",
    "            else:\n",
    "                my_embedding = torch.zeros(1, self.layer_output_size, 1, 1)\n",
    "\n",
    "            def copy_data(m, i, o):\n",
    "                my_embedding.copy_(o.data)\n",
    "\n",
    "            h = self.extraction_layer.register_forward_hook(copy_data)\n",
    "            with torch.no_grad():\n",
    "                h_x = self.model(image)\n",
    "            h.remove()\n",
    "\n",
    "            if tensor:\n",
    "                return my_embedding\n",
    "            else:\n",
    "                if self.model_name in ['alexnet', 'vgg']:\n",
    "                    return my_embedding.numpy()[0, :]\n",
    "                elif self.model_name == 'densenet':\n",
    "                    return torch.mean(my_embedding, (2, 3), True).numpy()[0, :, 0, 0]\n",
    "                else:\n",
    "                    return my_embedding.numpy()[0, :, 0, 0]\n",
    "\n",
    "    def _get_model_and_layer(self, model_name, layer):\n",
    "        if model_name.startswith('resnet') and not model_name.startswith('resnet-'):\n",
    "            model = getattr(models, model_name)(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model._modules.get('avgpool')\n",
    "                self.layer_output_size = self.RESNET_OUTPUT_SIZES[model_name]\n",
    "            else:\n",
    "                layer = model._modules.get(layer)\n",
    "            return model, layer\n",
    "        elif model_name == 'resnet-18':\n",
    "            model = models.resnet18(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model._modules.get('avgpool')\n",
    "                self.layer_output_size = 512\n",
    "            else:\n",
    "                layer = model._modules.get(layer)\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        elif model_name == 'alexnet':\n",
    "            model = models.alexnet(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model.classifier[-2]\n",
    "                self.layer_output_size = 4096\n",
    "            else:\n",
    "                layer = model.classifier[-layer]\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        elif model_name == 'vgg':\n",
    "            model = models.vgg11_bn(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model.classifier[-2]\n",
    "                self.layer_output_size = model.classifier[-1].in_features\n",
    "            else:\n",
    "                layer = model.classifier[-layer]\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        elif model_name == 'densenet':\n",
    "            model = models.densenet121(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model.features[-1]\n",
    "                self.layer_output_size = model.classifier.in_features\n",
    "            else:\n",
    "                raise KeyError('Un support %s for layer parameters' % model_name)\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        elif \"efficientnet\" in model_name:\n",
    "            if model_name == \"efficientnet_b0\":\n",
    "                model = models.efficientnet_b0(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b1\":\n",
    "                model = models.efficientnet_b1(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b2\":\n",
    "                model = models.efficientnet_b2(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b3\":\n",
    "                model = models.efficientnet_b3(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b4\":\n",
    "                model = models.efficientnet_b4(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b5\":\n",
    "                model = models.efficientnet_b5(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b6\":\n",
    "                model = models.efficientnet_b6(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b7\":\n",
    "                model = models.efficientnet_b7(pretrained=True)\n",
    "            else:\n",
    "                raise KeyError('Un support %s.' % model_name)\n",
    "\n",
    "            if layer == 'default':\n",
    "                layer = model.features\n",
    "                self.layer_output_size = self.EFFICIENTNET_OUTPUT_SIZES[model_name]\n",
    "            else:\n",
    "                raise KeyError('Un support %s for layer parameters' % model_name)\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        else:\n",
    "            raise KeyError('Model %s was not found' % model_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(embeddings):\n",
    "    return cosine_similarity(embeddings)\n",
    "\n",
    "def evaluate_model(embeddings, labels, threshold=0.5):\n",
    "    class_similarities = defaultdict(list)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for i in range(len(embeddings)):\n",
    "        for j in range(i + 1, len(embeddings)):\n",
    "            sim = cosine_similarity([embeddings[i]], [embeddings[j]])[0][0]\n",
    "            if labels[i] == labels[j]:\n",
    "                class_similarities[labels[i]].append(sim)\n",
    "                if sim > threshold:\n",
    "                    correct += 1\n",
    "            else:\n",
    "                if sim <= threshold:\n",
    "                    correct += 1\n",
    "            total += 1\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return accuracy, class_similarities\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for class_folder_name in os.listdir(folder):\n",
    "        class_folder_path = os.path.join(folder, class_folder_name)\n",
    "        if not os.path.isdir(class_folder_path):\n",
    "            continue\n",
    "        for filename in os.listdir(class_folder_path):\n",
    "            img_path = os.path.join(class_folder_path, filename)\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            images.append(img)\n",
    "            labels.append(class_folder_name)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 같은 label끼리의 유사도 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # 설정\n",
    "    model_names = ['resnet18', 'resnet50', 'efficientnet_b0', 'efficientnet_b7']\n",
    "    cuda = torch.cuda.is_available()\n",
    "    layer = 'default'\n",
    "    \n",
    "    # 예시 이미지 및 레이블 (사용자가 제공해야 함)\n",
    "    images = [Image.open('./data-gatter/train/BOLD/377985.jpg'), Image.open('./data-gatter/train/BOLD/378152.jpg'), Image.open('./data-gatter/train/BOLD/378225.jpg')]\n",
    "    labels = ['BOLD', 'BOLD', 'BOLD']\n",
    "    \n",
    "    # 평가 결과 저장\n",
    "    results = {}\n",
    "    \n",
    "    for model_name in model_names:\n",
    "        print(f\"Evaluating model {model_name}\")\n",
    "        img2vec = Img2Vec(cuda=cuda, model=model_name, layer=layer)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        embeddings = [img2vec.get_vec(img) for img in images]\n",
    "        embeddings = np.array(embeddings)\n",
    "        processing_time = (time.time() - start_time) / len(images)\n",
    "        \n",
    "        accuracy, class_similarities = evaluate_model(embeddings, labels)\n",
    "        \n",
    "        results[model_name] = {\n",
    "            'accuracy': accuracy,\n",
    "            'class_similarities': class_similarities,\n",
    "            'processing_time': processing_time\n",
    "        }\n",
    "        \n",
    "        print(f\"Model {model_name} - Accuracy: {accuracy}, Processing Time: {processing_time} per image\")\n",
    "    \n",
    "    # 결과 출력 또는 저장\n",
    "    for model_name, result in results.items():\n",
    "        print(f\"\\nModel: {model_name}\")\n",
    "        print(f\"Accuracy: {result['accuracy']}\")\n",
    "        print(f\"Processing Time per Image: {result['processing_time']}\")\n",
    "        print(f\"Class Similarities: {result['class_similarities']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 이미지 N개를 대상으로 각 이미지가 다른 N-1개의 이미지와 유사도를 계산하고, 이를 통해 잘 분류된 클래스와 잘못 분류된 클래스의 개수를 파악\n",
    "- threshold 변경해도 차이 별로x. (0.5 -> 0.3, 0.1, 0.8, 0.9 : 동일)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import certifi\n",
    "import os\n",
    "import ssl\n",
    "\n",
    "# SSL 인증서 설정\n",
    "os.environ['SSL_CERT_FILE'] = certifi.where()\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "class Img2Vec():\n",
    "    RESNET_OUTPUT_SIZES = {\n",
    "        'resnet18': 512,\n",
    "        'resnet34': 512,\n",
    "        'resnet50': 2048,\n",
    "        'resnet101': 2048,\n",
    "        'resnet152': 2048\n",
    "    }\n",
    "\n",
    "    EFFICIENTNET_OUTPUT_SIZES = {\n",
    "        'efficientnet_b0': 1280,\n",
    "        'efficientnet_b1': 1280,\n",
    "        'efficientnet_b2': 1408,\n",
    "        'efficientnet_b3': 1536,\n",
    "        'efficientnet_b4': 1792,\n",
    "        'efficientnet_b5': 2048,\n",
    "        'efficientnet_b6': 2304,\n",
    "        'efficientnet_b7': 2560\n",
    "    }\n",
    "\n",
    "    def __init__(self, cuda=False, model='resnet18', layer='default', layer_output_size=512, gpu=0):\n",
    "        self.device = torch.device(f\"cuda:{gpu}\" if cuda else \"cpu\")\n",
    "        self.layer_output_size = layer_output_size\n",
    "        self.model_name = model\n",
    "\n",
    "        self.model, self.extraction_layer = self._get_model_and_layer(model, layer)\n",
    "\n",
    "        self.model = self.model.to(self.device)\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "        self.scaler = transforms.Resize((224, 224))\n",
    "        self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                              std=[0.229, 0.224, 0.225])\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "\n",
    "    def get_vec(self, img, tensor=False):\n",
    "        if type(img) == list:\n",
    "            a = [self.normalize(self.to_tensor(self.scaler(im))) for im in img]\n",
    "            images = torch.stack(a).to(self.device)\n",
    "            if self.model_name in ['alexnet', 'vgg']:\n",
    "                my_embedding = torch.zeros(len(img), self.layer_output_size)\n",
    "            elif self.model_name == 'densenet' or 'efficientnet' in self.model_name:\n",
    "                my_embedding = torch.zeros(len(img), self.layer_output_size, 7, 7)\n",
    "            else:\n",
    "                my_embedding = torch.zeros(len(img), self.layer_output_size, 1, 1)\n",
    "\n",
    "            def copy_data(m, i, o):\n",
    "                my_embedding.copy_(o.data)\n",
    "\n",
    "            h = self.extraction_layer.register_forward_hook(copy_data)\n",
    "            with torch.no_grad():\n",
    "                h_x = self.model(images)\n",
    "            h.remove()\n",
    "\n",
    "            if tensor:\n",
    "                return my_embedding\n",
    "            else:\n",
    "                if self.model_name in ['alexnet', 'vgg']:\n",
    "                    return my_embedding.numpy()[:, :]\n",
    "                elif self.model_name == 'densenet' or 'efficientnet' in self.model_name:\n",
    "                    return torch.mean(my_embedding, (2, 3), True).numpy()[:, :, 0, 0]\n",
    "                else:\n",
    "                    return my_embedding.numpy()[:, :, 0, 0]\n",
    "        else:\n",
    "            image = self.normalize(self.to_tensor(self.scaler(img))).unsqueeze(0).to(self.device)\n",
    "\n",
    "            if self.model_name in ['alexnet', 'vgg']:\n",
    "                my_embedding = torch.zeros(1, self.layer_output_size)\n",
    "            elif self.model_name == 'densenet' or 'efficientnet' in self.model_name:\n",
    "                my_embedding = torch.zeros(1, self.layer_output_size, 7, 7)\n",
    "            else:\n",
    "                my_embedding = torch.zeros(1, self.layer_output_size, 1, 1)\n",
    "\n",
    "            def copy_data(m, i, o):\n",
    "                my_embedding.copy_(o.data)\n",
    "\n",
    "            h = self.extraction_layer.register_forward_hook(copy_data)\n",
    "            with torch.no_grad():\n",
    "                h_x = self.model(image)\n",
    "            h.remove()\n",
    "\n",
    "            if tensor:\n",
    "                return my_embedding\n",
    "            else:\n",
    "                if self.model_name in ['alexnet', 'vgg']:\n",
    "                    return my_embedding.numpy()[0, :]\n",
    "                elif self.model_name == 'densenet':\n",
    "                    return torch.mean(my_embedding, (2, 3), True).numpy()[0, :, 0, 0]\n",
    "                else:\n",
    "                    return my_embedding.numpy()[0, :, 0, 0]\n",
    "\n",
    "    def _get_model_and_layer(self, model_name, layer):\n",
    "        if model_name.startswith('resnet') and not model_name.startswith('resnet-'):\n",
    "            model = getattr(models, model_name)(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model._modules.get('avgpool')\n",
    "                self.layer_output_size = self.RESNET_OUTPUT_SIZES[model_name]\n",
    "            else:\n",
    "                layer = model._modules.get(layer)\n",
    "            return model, layer\n",
    "        elif model_name == 'resnet-18':\n",
    "            model = models.resnet18(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model._modules.get('avgpool')\n",
    "                self.layer_output_size = 512\n",
    "            else:\n",
    "                layer = model._modules.get(layer)\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        elif model_name == 'alexnet':\n",
    "            model = models.alexnet(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model.classifier[-2]\n",
    "                self.layer_output_size = 4096\n",
    "            else:\n",
    "                layer = model.classifier[-layer]\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        elif model_name == 'vgg':\n",
    "            model = models.vgg11_bn(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model.classifier[-2]\n",
    "                self.layer_output_size = model.classifier[-1].in_features\n",
    "            else:\n",
    "                layer = model.classifier[-layer]\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        elif model_name == 'densenet':\n",
    "            model = models.densenet121(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model.features[-1]\n",
    "                self.layer_output_size = model.classifier.in_features\n",
    "            else:\n",
    "                raise KeyError('Un support %s for layer parameters' % model_name)\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        elif \"efficientnet\" in model_name:\n",
    "            if model_name == \"efficientnet_b0\":\n",
    "                model = models.efficientnet_b0(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b1\":\n",
    "                model = models.efficientnet_b1(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b2\":\n",
    "                model = models.efficientnet_b2(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b3\":\n",
    "                model = models.efficientnet_b3(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b4\":\n",
    "                model = models.efficientnet_b4(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b5\":\n",
    "                model = models.efficientnet_b5(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b6\":\n",
    "                model = models.efficientnet_b6(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b7\":\n",
    "                model = models.efficientnet_b7(pretrained=True)\n",
    "            else:\n",
    "                raise KeyError('Un support %s.' % model_name)\n",
    "\n",
    "            if layer == 'default':\n",
    "                layer = model.features\n",
    "                self.layer_output_size = self.EFFICIENTNET_OUTPUT_SIZES[model_name]\n",
    "            else:\n",
    "                raise KeyError('Un support %s for layer parameters' % model_name)\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        else:\n",
    "            raise KeyError('Model %s was not found' % model_name)\n",
    "\n",
    "def calculate_similarity(embeddings):\n",
    "    return cosine_similarity(embeddings)\n",
    "\n",
    "def evaluate_model(embeddings, labels, threshold=0.5):\n",
    "    class_similarities = defaultdict(list)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for i in range(len(embeddings)):\n",
    "        for j in range(i + 1, len(embeddings)):\n",
    "            sim = cosine_similarity([embeddings[i]], [embeddings[j]])[0][0]\n",
    "            if labels[i] == labels[j]:\n",
    "                class_similarities[labels[i]].append(sim)\n",
    "                if sim > threshold:\n",
    "                    correct += 1\n",
    "            else:\n",
    "                if sim <= threshold:\n",
    "                    correct += 1\n",
    "            total += 1\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return accuracy, class_similarities\n",
    "\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    valid_image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']  # 허용된 이미지 파일 확장자 목록\n",
    "    for class_folder_name in os.listdir(folder):\n",
    "        class_folder_path = os.path.join(folder, class_folder_name)\n",
    "        if not os.path.isdir(class_folder_path):\n",
    "            continue\n",
    "        for filename in os.listdir(class_folder_path):\n",
    "            img_path = os.path.join(class_folder_path, filename)\n",
    "            if os.path.splitext(filename)[1].lower() in valid_image_extensions:  # 파일 확장자 확인\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "                images.append(img)\n",
    "                labels.append(class_folder_name)\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "def main():\n",
    "    # 설정\n",
    "    model_names = ['resnet18', 'resnet50', 'efficientnet_b0', 'efficientnet_b7']\n",
    "    cuda = torch.cuda.is_available()\n",
    "    layer = 'default'\n",
    "    \n",
    "    # 폴더에서 이미지와 레이블 불러오기\n",
    "    folder_path = './data-gatter/train'\n",
    "    images, labels = load_images_from_folder(folder_path)\n",
    "    \n",
    "    # 각 클래스당 최소 2개 이상의 이미지가 필요\n",
    "    required_label_count = 2\n",
    "    # 각 카테고리별 이미지 수 확인\n",
    "    label_counts = {label: labels.count(label) for label in set(labels)}\n",
    "    \n",
    "    # 카테고리별 이미지 수가 충분한지 확인\n",
    "    if any(count < required_label_count for count in label_counts.values()):\n",
    "        print(\"각 클래스에는 최소 2개의 이미지가 필요합니다.\")\n",
    "        return\n",
    "\n",
    "    # 평가 결과 저장\n",
    "    results = {}\n",
    "    \n",
    "    for model_name in model_names:\n",
    "        print(f\"Evaluating model {model_name}\")\n",
    "        img2vec = Img2Vec(cuda=cuda, model=model_name, layer=layer)\n",
    "        \n",
    "        # 임베딩 추출\n",
    "        start_time = time.time()\n",
    "        embeddings = [img2vec.get_vec(img) for img in images]\n",
    "        embeddings = np.array(embeddings)\n",
    "        processing_time = (time.time() - start_time) / len(images)\n",
    "        \n",
    "        # 평가 모델 사용하여 정확도 계산\n",
    "        threshold = 0.5\n",
    "        accuracy, class_similarities = evaluate_model(embeddings, labels, threshold)\n",
    "        \n",
    "        # 올바르게 분류된 데이터 수 및 분류되지 않은 데이터 수 계산\n",
    "        correct_classifications = 0\n",
    "        incorrect_classifications = 0\n",
    "\n",
    "        for i, embedding in enumerate(embeddings):\n",
    "            similarities = []\n",
    "            for j in range(len(images)):\n",
    "                if i != j:\n",
    "                    sim = cosine_similarity([embedding], [embeddings[j]])[0][0]\n",
    "                    similarities.append((sim, labels[j]))\n",
    "            \n",
    "            # 유사도 기준으로 정렬\n",
    "            similarities.sort(reverse=True, key=lambda x: x[0])\n",
    "            \n",
    "            # 가장 유사한 이미지와 해당 유사도 출력\n",
    "            most_similar_label = similarities[0][1]\n",
    "            \n",
    "            # 분류 결과 확인\n",
    "            if most_similar_label == labels[i]:\n",
    "                correct_classifications += 1\n",
    "            else:\n",
    "                incorrect_classifications += 1\n",
    "        \n",
    "        # 정확도 수정_\n",
    "        total_images = correct_classifications + incorrect_classifications\n",
    "        accuracy = correct_classifications / total_images\n",
    "        \n",
    "        results[model_name] = {\n",
    "            'accuracy': accuracy,\n",
    "            'class_similarities': class_similarities,\n",
    "            'correct_classifications': correct_classifications,\n",
    "            'incorrect_classifications': incorrect_classifications,\n",
    "            'processing_time': processing_time\n",
    "        }\n",
    "        \n",
    "        print(f\"Model {model_name} - Correct Classifications: {correct_classifications}, Incorrect Classifications: {incorrect_classifications}, Processing Time: {processing_time} per image\")\n",
    "    \n",
    "    # 결과 출력 또는 저장\n",
    "    for model_name, result in results.items():\n",
    "        print(f\"\\nModel: {model_name}\")\n",
    "        print(f\"Accuracy: {result['accuracy']}\")\n",
    "        print(f\"Correct Classifications: {result['correct_classifications']}\")\n",
    "        print(f\"Incorrect Classifications: {result['incorrect_classifications']}\")\n",
    "        print(f\"Processing Time per Image: {result['processing_time']}\")\n",
    "        print(f\"Class Similarities: {result['class_similarities']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 결과\n",
    "Model: resnet18\n",
    "Correct Classifications: 31\n",
    "Incorrect Classifications: 5\n",
    "Processing Time per Image: 0.05470755365159777\n",
    "\n",
    "Model: resnet50\n",
    "Correct Classifications: 30\n",
    "Incorrect Classifications: 6\n",
    "Processing Time per Image: 0.1096413532892863\n",
    "\n",
    "Model: efficientnet_b0\n",
    "Correct Classifications: 16\n",
    "Incorrect Classifications: 20\n",
    "Processing Time per Image: 0.06240766578250461\n",
    "\n",
    "Model: efficientnet_b3\n",
    "Correct Classifications: 21\n",
    "Incorrect Classifications: 15\n",
    "Processing Time per Image: 0.10402288701799181\n",
    "(venv) hahyeonji@hahyeonjiui-MacBookPro ImageImbedding % "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 에서 각 이미지의 임베딩 값도 같이 출력, (accuracy 때문에 대혼란) - 여기선 evaluate_model 함수의 accuracy이고 classification 결과는 main 에서의 분류결과를 나타낸것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import certifi\n",
    "import os\n",
    "import ssl\n",
    "\n",
    "# SSL 인증서 설정\n",
    "os.environ['SSL_CERT_FILE'] = certifi.where()\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# 이미지를 벡터로 변환(임베딩)하는 역할 (이미지 ->> 벡터)\n",
    "class Img2Vec():\n",
    "    RESNET_OUTPUT_SIZES = {\n",
    "        'resnet18': 512,\n",
    "        'resnet34': 512,\n",
    "        'resnet50': 2048,\n",
    "        'resnet101': 2048,\n",
    "        'resnet152': 2048\n",
    "    }\n",
    "\n",
    "    EFFICIENTNET_OUTPUT_SIZES = {\n",
    "        'efficientnet_b0': 1280,\n",
    "        'efficientnet_b1': 1280,\n",
    "        'efficientnet_b2': 1408,\n",
    "        'efficientnet_b3': 1536,\n",
    "        'efficientnet_b4': 1792,\n",
    "        'efficientnet_b5': 2048,\n",
    "        'efficientnet_b6': 2304,\n",
    "        'efficientnet_b7': 2560\n",
    "    }\n",
    "\n",
    "    def __init__(self, cuda=False, model='resnet18', layer='default', layer_output_size=512, gpu=0):\n",
    "        self.device = torch.device(f\"cuda:{gpu}\" if cuda else \"cpu\")\n",
    "        self.layer_output_size = layer_output_size\n",
    "        self.model_name = model\n",
    "\n",
    "        self.model, self.extraction_layer = self._get_model_and_layer(model, layer)\n",
    "\n",
    "        self.model = self.model.to(self.device)\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "        self.scaler = transforms.Resize((224, 224))\n",
    "        self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                              std=[0.229, 0.224, 0.225])\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "\n",
    "    # 이미지를 입력으로 받아 벡터로 변환\n",
    "    def get_vec(self, img, tensor=False):\n",
    "        if type(img) == list:\n",
    "            a = [self.normalize(self.to_tensor(self.scaler(im))) for im in img]\n",
    "            images = torch.stack(a).to(self.device)\n",
    "            if self.model_name in ['alexnet', 'vgg']:\n",
    "                my_embedding = torch.zeros(len(img), self.layer_output_size)\n",
    "            elif self.model_name == 'densenet' or 'efficientnet' in self.model_name:\n",
    "                my_embedding = torch.zeros(len(img), self.layer_output_size, 7, 7)\n",
    "            else:\n",
    "                my_embedding = torch.zeros(len(img), self.layer_output_size, 1, 1)\n",
    "\n",
    "            def copy_data(m, i, o):\n",
    "                my_embedding.copy_(o.data)\n",
    "\n",
    "            h = self.extraction_layer.register_forward_hook(copy_data)\n",
    "            with torch.no_grad():\n",
    "                h_x = self.model(images)\n",
    "            h.remove()\n",
    "\n",
    "            if tensor:\n",
    "                return my_embedding\n",
    "            else:\n",
    "                if self.model_name in ['alexnet', 'vgg']:\n",
    "                    return my_embedding.numpy()[:, :]\n",
    "                elif self.model_name == 'densenet' or 'efficientnet' in self.model_name:\n",
    "                    return torch.mean(my_embedding, (2, 3), True).numpy()[:, :, 0, 0]\n",
    "                else:\n",
    "                    return my_embedding.numpy()[:, :, 0, 0]\n",
    "        else:\n",
    "            image = self.normalize(self.to_tensor(self.scaler(img))).unsqueeze(0).to(self.device)\n",
    "\n",
    "            if self.model_name in ['alexnet', 'vgg']:\n",
    "                my_embedding = torch.zeros(1, self.layer_output_size)\n",
    "            elif self.model_name == 'densenet' or 'efficientnet' in self.model_name:\n",
    "                my_embedding = torch.zeros(1, self.layer_output_size, 7, 7)\n",
    "            else:\n",
    "                my_embedding = torch.zeros(1, self.layer_output_size, 1, 1)\n",
    "\n",
    "            def copy_data(m, i, o):\n",
    "                my_embedding.copy_(o.data)\n",
    "\n",
    "            h = self.extraction_layer.register_forward_hook(copy_data)\n",
    "            with torch.no_grad():\n",
    "                h_x = self.model(image)\n",
    "            h.remove()\n",
    "\n",
    "            if tensor:\n",
    "                return my_embedding\n",
    "            else:\n",
    "                if self.model_name in ['alexnet', 'vgg']:\n",
    "                    return my_embedding.numpy()[0, :]\n",
    "                elif self.model_name == 'densenet':\n",
    "                    return torch.mean(my_embedding, (2, 3), True).numpy()[0, :, 0, 0]\n",
    "                else:\n",
    "                    return my_embedding.numpy()[0, :, 0, 0]\n",
    "\n",
    "    # 주어진 모델 이름에 따라 모델과 해당 레이어 가져옴\n",
    "    def _get_model_and_layer(self, model_name, layer):\n",
    "        if model_name.startswith('resnet') and not model_name.startswith('resnet-'):\n",
    "            model = getattr(models, model_name)(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model._modules.get('avgpool')\n",
    "                self.layer_output_size = self.RESNET_OUTPUT_SIZES[model_name]\n",
    "            else:\n",
    "                layer = model._modules.get(layer)\n",
    "            return model, layer\n",
    "        elif model_name == 'resnet-18':\n",
    "            model = models.resnet18(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model._modules.get('avgpool')\n",
    "                self.layer_output_size = 512\n",
    "            else:\n",
    "                layer = model._modules.get(layer)\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        elif model_name == 'alexnet':\n",
    "            model = models.alexnet(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model.classifier[-2]\n",
    "                self.layer_output_size = 4096\n",
    "            else:\n",
    "                layer = model.classifier[-layer]\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        elif model_name == 'vgg':\n",
    "            model = models.vgg11_bn(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model.classifier[-2]\n",
    "                self.layer_output_size = model.classifier[-1].in_features\n",
    "            else:\n",
    "                layer = model.classifier[-layer]\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        elif model_name == 'densenet':\n",
    "            model = models.densenet121(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model.features[-1]\n",
    "                self.layer_output_size = model.classifier.in_features\n",
    "            else:\n",
    "                raise KeyError('Un support %s for layer parameters' % model_name)\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        elif \"efficientnet\" in model_name:\n",
    "            if model_name == \"efficientnet_b0\":\n",
    "                model = models.efficientnet_b0(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b1\":\n",
    "                model = models.efficientnet_b1(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b2\":\n",
    "                model = models.efficientnet_b2(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b3\":\n",
    "                model = models.efficientnet_b3(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b4\":\n",
    "                model = models.efficientnet_b4(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b5\":\n",
    "                model = models.efficientnet_b5(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b6\":\n",
    "                model = models.efficientnet_b6(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b7\":\n",
    "                model = models.efficientnet_b7(pretrained=True)\n",
    "            else:\n",
    "                raise KeyError('Un support %s.' % model_name)\n",
    "\n",
    "            if layer == 'default':\n",
    "                layer = model.features\n",
    "                self.layer_output_size = self.EFFICIENTNET_OUTPUT_SIZES[model_name]\n",
    "            else:\n",
    "                raise KeyError('Un support %s for layer parameters' % model_name)\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        else:\n",
    "            raise KeyError('Model %s was not found' % model_name)\n",
    "\n",
    "# 주어진 임베딩(벡터)간의 코사인 유사도 계산 - 두 벡터가 얼마나 유사한지 측정\n",
    "def calculate_similarity(embeddings):\n",
    "    return cosine_similarity(embeddings)\n",
    "\n",
    "# 주어진 임베딩(벡터)와 레이블 사용해 모델의 정확도 평가 - 유사도 임계값을 기준으로 올바르게 분류된 쌍의 비율을 계산\n",
    "def evaluate_model(embeddings, labels, threshold):\n",
    "    class_similarities = defaultdict(list)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for i in range(len(embeddings)):\n",
    "        for j in range(i + 1, len(embeddings)):\n",
    "            sim = cosine_similarity([embeddings[i]], [embeddings[j]])[0][0]\n",
    "            if labels[i] == labels[j]:\n",
    "                class_similarities[labels[i]].append(sim)\n",
    "                if sim > threshold:\n",
    "                    correct += 1\n",
    "            else:\n",
    "                if sim <= threshold:\n",
    "                    correct += 1\n",
    "            total += 1\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return accuracy, class_similarities\n",
    "\n",
    "# 주어진 폴더에서 이미지 읽어오고, 이미지와 해당 레이블(폴더 이름) 반환\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    valid_image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']  # 허용된 이미지 파일 확장자 목록\n",
    "    for class_folder_name in os.listdir(folder):\n",
    "        class_folder_path = os.path.join(folder, class_folder_name)\n",
    "        if not os.path.isdir(class_folder_path):\n",
    "            continue\n",
    "        for filename in os.listdir(class_folder_path):\n",
    "            img_path = os.path.join(class_folder_path, filename)\n",
    "            if os.path.splitext(filename)[1].lower() in valid_image_extensions:  # 파일 확장자 확인\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "                images.append(img)\n",
    "                labels.append(class_folder_name)\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "def main():\n",
    "    # 설정\n",
    "    model_names = ['resnet18', 'resnet50', 'efficientnet_b0', 'efficientnet_b7']\n",
    "    cuda = torch.cuda.is_available()\n",
    "    layer = 'default'\n",
    "    \n",
    "    # 폴더에서 이미지와 레이블 불러오기\n",
    "    folder_path = './data-gatter/train'\n",
    "    images, labels = load_images_from_folder(folder_path)\n",
    "    \n",
    "    # 각 클래스당 최소 2개 이상의 이미지가 필요\n",
    "    required_label_count = 2\n",
    "    # 각 카테고리별 이미지 수 확인\n",
    "    label_counts = {label: labels.count(label) for label in set(labels)}\n",
    "    \n",
    "    # 카테고리별 이미지 수가 충분한지 확인\n",
    "    if any(count < required_label_count for count in label_counts.values()):\n",
    "        print(\"각 클래스에는 최소 2개의 이미지가 필요합니다.\")\n",
    "        return\n",
    "\n",
    "    # 평가 결과 저장\n",
    "    results = {}\n",
    "    \n",
    "    for model_name in model_names:\n",
    "        print(f\"Evaluating model {model_name}\")\n",
    "        img2vec = Img2Vec(cuda=cuda, model=model_name, layer=layer)\n",
    "        \n",
    "        # 임베딩 추출\n",
    "        start_time = time.time()\n",
    "        embeddings = [img2vec.get_vec(img) for img in images]\n",
    "        embeddings = np.array(embeddings)\n",
    "        processing_time = (time.time() - start_time) / len(images)\n",
    "        \n",
    "        # 평가 모델 사용하여 정확도 계산\n",
    "        threshold = 0.5\n",
    "        accuracy, class_similarities = evaluate_model(embeddings, labels, threshold)\n",
    "        \n",
    "        # 잘 분류된 클래스와 잘못 분류된 클래스 계산\n",
    "        correct_classifications = defaultdict(int)\n",
    "        incorrect_classifications = defaultdict(int)\n",
    "\n",
    "        total_correct = 0\n",
    "        total_incorrect = 0\n",
    "\n",
    "        for i, embedding in enumerate(embeddings):\n",
    "            similarities = []\n",
    "            for j in range(len(images)):\n",
    "                if i != j:\n",
    "                    sim = cosine_similarity([embedding], [embeddings[j]])[0][0]\n",
    "                    similarities.append((sim, labels[j]))\n",
    "            \n",
    "            # 유사도 기준으로 정렬\n",
    "            similarities.sort(reverse=True, key=lambda x: x[0])\n",
    "            \n",
    "            # 가장 유사한 이미지의 레이블\n",
    "            most_similar_label = similarities[0][1]\n",
    "            \n",
    "            # 분류 결과 확인\n",
    "            if most_similar_label == labels[i]:\n",
    "                correct_classifications[labels[i]] += 1\n",
    "                total_correct += 1\n",
    "            else:\n",
    "                incorrect_classifications[labels[i]] += 1\n",
    "                total_incorrect += 1\n",
    "        \n",
    "        results[model_name] = {\n",
    "            'accuracy': accuracy,\n",
    "            'class_similarities': class_similarities,\n",
    "            'correct_classifications': correct_classifications,\n",
    "            'incorrect_classifications': incorrect_classifications,\n",
    "            'processing_time': processing_time,\n",
    "            'total_correct': total_correct,\n",
    "            'total_incorrect': total_incorrect\n",
    "        }\n",
    "        \n",
    "        print(f\"Model {model_name} - Processing Time: {processing_time} per image\")\n",
    "    \n",
    "    # 결과 출력 또는 저장\n",
    "    for model_name, result in results.items():\n",
    "        print(f\"\\nModel: {model_name}\")\n",
    "        print(f\"Accuracy: {result['accuracy']}\")\n",
    "        print(f\"Total Correct Classifications: {result['total_correct']}\")\n",
    "        print(f\"Total Incorrect Classifications: {result['total_incorrect']}\")\n",
    "        print(f\"Processing Time per Image: {result['processing_time']}\")\n",
    "        print(f\"Class Similarities: {result['class_similarities']}\")\n",
    "        print(\"Correct Classifications:\")\n",
    "        for label, count in result['correct_classifications'].items():\n",
    "            print(f\"  {label}: {count}\")\n",
    "        print(\"Incorrect Classifications:\")\n",
    "        for label, count in result['incorrect_classifications'].items():\n",
    "            print(f\"  {label}: {count}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model: resnet18\n",
    "Accuracy: 0.14285714285714285\n",
    "Total Correct Classifications: 31\n",
    "Total Incorrect Classifications: 5\n",
    "Processing Time per Image: 0.06275461117426555\n",
    "Class Similarities: defaultdict(<class 'list'>, {'DUST': [0.6001026, 0.53807384, 0.9493884, 0.54201394, 0.82975245, 0.8602035, 0.61878675, 0.87639034, 0.65792805, 0.5657732, 0.9791348, 0.61132973, 0.5671531, 0.915514, 0.61289144], 'BURR': [0.7781271, 0.9284715, 0.76342845, 0.8108454, 0.7897095, 0.7741957, 0.80353606, 0.7535825, 0.81127834, 0.78037083, 0.8186377, 0.8189117, 0.81996256, 0.896101, 0.84166086], 'DOT': [0.8536985, 0.85882974, 0.8305161, 0.84968317, 0.8298479, 0.9281166, 0.88934636, 0.83101875, 0.85062665, 0.92213213, 0.8681096, 0.8182904, 0.8897617, 0.81204057, 0.8109412], 'BUBBLE': [0.7703301, 0.7713212, 0.6419724, 0.89030564, 0.79348904, 0.5757905, 0.7169981, 0.76072043, 0.96819353, 0.6010142, 0.7506037, 0.596917, 0.6340326, 0.7169784, 0.7654363], 'BOLD': [0.7789995, 0.88758177, 0.7582421, 0.85858905, 0.81812966, 0.73470795, 0.9518256, 0.695719, 0.9369452, 0.7190074, 0.8716805, 0.79979587, 0.6591646, 0.92920244, 0.72366077], 'DAMAGE': [0.66376376, 0.8035166, 0.8039102, 0.73163474, 0.78607035, 0.7310408, 0.7571741, 0.6395329, 0.67981064, 0.86540115, 0.73969877, 0.8165145, 0.71747375, 0.8027081, 0.70580083]})\n",
    "Correct Classifications:\n",
    "  DUST: 6\n",
    "  BURR: 4\n",
    "  DOT: 6\n",
    "  BUBBLE: 5\n",
    "  BOLD: 6\n",
    "  DAMAGE: 4\n",
    "Incorrect Classifications:\n",
    "  BURR: 2\n",
    "  BUBBLE: 1\n",
    "  DAMAGE: 2\n",
    "\n",
    "Model: resnet50\n",
    "Accuracy: 0.14285714285714285\n",
    "Total Correct Classifications: 30\n",
    "Total Incorrect Classifications: 6\n",
    "Processing Time per Image: 0.12785636054144967\n",
    "Class Similarities: defaultdict(<class 'list'>, {'DUST': [0.61705756, 0.55926436, 0.9567903, 0.55929494, 0.92152, 0.9219435, 0.6773299, 0.90910363, 0.70902765, 0.6190162, 0.98842055, 0.6515464, 0.61400175, 0.95483375, 0.647736], 'BURR': [0.777568, 0.9020001, 0.8261082, 0.862092, 0.80820096, 0.80475134, 0.8562846, 0.7108218, 0.80849266, 0.868747, 0.85221004, 0.83971417, 0.8113427, 0.8728665, 0.80198], 'DOT': [0.86121213, 0.8421737, 0.7843202, 0.8679179, 0.8614478, 0.9034014, 0.8598916, 0.87437975, 0.8510826, 0.9050518, 0.8790137, 0.83261365, 0.8969681, 0.83286107, 0.8773044], 'BUBBLE': [0.7640948, 0.8246045, 0.6435535, 0.88657117, 0.78054756, 0.6276556, 0.76226246, 0.7135753, 0.9754814, 0.6203302, 0.8142369, 0.6227167, 0.6036109, 0.7319559, 0.71531487], 'BOLD': [0.77138364, 0.9042731, 0.7793336, 0.8334779, 0.8077489, 0.7983791, 0.9538292, 0.80720913, 0.91110194, 0.7957515, 0.8865381, 0.8069916, 0.8049986, 0.9154985, 0.8228679], 'DAMAGE': [0.7637502, 0.835957, 0.84270084, 0.79230416, 0.84850043, 0.7361436, 0.7541573, 0.6820943, 0.6954595, 0.8437828, 0.7864474, 0.7701396, 0.7554374, 0.84396756, 0.73614895]})\n",
    "Correct Classifications:\n",
    "  DUST: 6\n",
    "  BURR: 4\n",
    "  DOT: 5\n",
    "  BUBBLE: 5\n",
    "  BOLD: 6\n",
    "  DAMAGE: 4\n",
    "Incorrect Classifications:\n",
    "  BURR: 2\n",
    "  DOT: 1\n",
    "  BUBBLE: 1\n",
    "  DAMAGE: 2\n",
    "\n",
    "Model: efficientnet_b0\n",
    "Accuracy: 0.7507936507936508\n",
    "Total Correct Classifications: 16\n",
    "Total Incorrect Classifications: 20\n",
    "Processing Time per Image: 0.06536852651172215\n",
    "Class Similarities: defaultdict(<class 'list'>, {'DUST': [-0.13152933, -0.09557498, 0.7509824, -0.07606883, 0.6126944, 0.91317904, -0.15710256, 0.91592324, -0.18517235, -0.1080755, 0.9902494, -0.13842978, -0.09473304, 0.80374783, -0.12725697], 'BURR': [-0.082971714, 0.89776844, -0.14330362, -0.09794522, 0.53148186, -0.120223686, 0.6769149, 0.36531407, 0.009515939, -0.16067114, -0.111673675, 0.4623048, 0.62933224, 0.01577626, 0.0039786287], 'DOT': [0.025647188, 0.0123753995, 0.0012437142, 0.033796452, 0.052951697, 0.8054329, 0.67700106, 0.83804, 0.42725527, 0.89325184, 0.8351203, 0.31471747, 0.7667023, 0.20714186, 0.36583087], 'BUBBLE': [0.6926166, 0.2729605, 0.26380616, 0.22804569, 0.4842757, 0.2303946, 0.29071224, 0.20908237, 0.69211555, 0.58204913, 0.3759123, 0.16557488, 0.5065632, 0.23898357, 0.23616421], 'BOLD': [-0.11430626, 0.66154224, -0.04425245, 0.54309666, -0.104347184, -0.10720118, 0.906031, -0.13503286, 0.9655404, -0.049425516, 0.5853907, -0.099055395, -0.060948595, 0.8883899, -0.12364669], 'DAMAGE': [-0.1534439, 0.19700375, 0.059871707, 0.35977662, 0.0523519, 0.016384955, 0.2167495, -0.01772985, 0.31034195, 0.1930649, 0.16777751, 0.3233468, 0.0778311, 0.4676621, 0.12329185]})\n",
    "Correct Classifications:\n",
    "  DUST: 5\n",
    "  BURR: 1\n",
    "  DOT: 1\n",
    "  BUBBLE: 5\n",
    "  BOLD: 2\n",
    "  DAMAGE: 2\n",
    "Incorrect Classifications:\n",
    "  DUST: 1\n",
    "  BURR: 5\n",
    "  DOT: 5\n",
    "  BUBBLE: 1\n",
    "  BOLD: 4\n",
    "  DAMAGE: 4\n",
    "\n",
    "Model: efficientnet_b7\n",
    "Accuracy: 0.2857142857142857\n",
    "Total Correct Classifications: 23\n",
    "Total Incorrect Classifications: 13\n",
    "Processing Time per Image: 0.2156504193941752\n",
    "Class Similarities: defaultdict(<class 'list'>, {'DUST': [0.34381083, 0.21505383, 0.98427415, 0.43858957, 0.85019755, 0.6931971, 0.2874999, 0.7203119, 0.48054194, 0.15253966, 0.94625175, 0.42242616, 0.39250416, 0.82188916, 0.5656338], 'BURR': [0.7793501, 0.85145676, 0.7125516, 0.7582659, 0.9003099, 0.72041523, 0.84242105, 0.78972703, 0.81107163, 0.65737516, 0.6189538, 0.90561193, 0.65487945, 0.7729525, 0.70785105], 'DOT': [0.8393124, 0.8868328, 0.89319074, 0.8743707, 0.7206726, 0.9278182, 0.8718964, 0.8715538, 0.82095957, 0.90687144, 0.90973717, 0.77878416, 0.9297477, 0.82158494, 0.81408644], 'BUBBLE': [0.87683886, 0.46940288, 0.82717264, 0.75214934, 0.8502173, 0.13090758, 0.93697786, 0.4519376, 0.9821197, 0.15053894, 0.8278872, 0.12729174, 0.42500865, 0.9308605, 0.4492649], 'BOLD': [0.55928755, 0.763012, 0.495019, 0.81053996, 0.503875, 0.48287305, 0.9641124, 0.64014244, 0.9356107, 0.44301492, 0.7821515, 0.43561652, 0.61919355, 0.9355072, 0.6175692], 'DAMAGE': [0.3107702, 0.7847667, 0.7821056, 0.5105388, 0.81290734, 0.4639718, 0.19325778, 0.6477406, 0.31198722, 0.85771215, 0.63285905, 0.81702805, 0.2930688, 0.8692167, 0.4246933]})\n",
    "Correct Classifications:\n",
    "  DUST: 4\n",
    "  BURR: 1\n",
    "  DOT: 6\n",
    "  BUBBLE: 5\n",
    "  BOLD: 5\n",
    "  DAMAGE: 2\n",
    "Incorrect Classifications:\n",
    "  DUST: 2\n",
    "  BURR: 5\n",
    "  BUBBLE: 1\n",
    "  BOLD: 1\n",
    "  DAMAGE: 4\n",
    "(venv) hahyeonji@hahyeonjiui-MacBookPro ImageImbedding % \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "============================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "============================================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import certifi\n",
    "import os\n",
    "import ssl\n",
    "\n",
    "# SSL 인증서 설정\n",
    "os.environ['SSL_CERT_FILE'] = certifi.where()\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "class Img2Vec():\n",
    "    RESNET_OUTPUT_SIZES = {\n",
    "        'resnet18': 512,\n",
    "        'resnet34': 512,\n",
    "        'resnet50': 2048,\n",
    "        'resnet101': 2048,\n",
    "        'resnet152': 2048\n",
    "    }\n",
    "\n",
    "    EFFICIENTNET_OUTPUT_SIZES = {\n",
    "        'efficientnet_b0': 1280,\n",
    "        'efficientnet_b1': 1280,\n",
    "        'efficientnet_b2': 1408,\n",
    "        'efficientnet_b3': 1536,\n",
    "        'efficientnet_b4': 1792,\n",
    "        'efficientnet_b5': 2048,\n",
    "        'efficientnet_b6': 2304,\n",
    "        'efficientnet_b7': 2560\n",
    "    }\n",
    "\n",
    "    def __init__(self, cuda=False, model='resnet18', layer='default', layer_output_size=512, gpu=0):\n",
    "        self.device = torch.device(f\"cuda:{gpu}\" if cuda else \"cpu\")\n",
    "        self.layer_output_size = layer_output_size\n",
    "        self.model_name = model\n",
    "\n",
    "        self.model, self.extraction_layer = self._get_model_and_layer(model, layer)\n",
    "\n",
    "        self.model = self.model.to(self.device)\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "        self.scaler = transforms.Resize((224, 224))\n",
    "        self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                              std=[0.229, 0.224, 0.225])\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "\n",
    "    def get_vec(self, img, tensor=False):\n",
    "        if type(img) == list:\n",
    "            a = [self.normalize(self.to_tensor(self.scaler(im))) for im in img]\n",
    "            images = torch.stack(a).to(self.device)\n",
    "            if self.model_name in ['alexnet', 'vgg']:\n",
    "                my_embedding = torch.zeros(len(img), self.layer_output_size)\n",
    "            elif self.model_name == 'densenet' or 'efficientnet' in self.model_name:\n",
    "                my_embedding = torch.zeros(len(img), self.layer_output_size, 7, 7)\n",
    "            else:\n",
    "                my_embedding = torch.zeros(len(img), self.layer_output_size, 1, 1)\n",
    "\n",
    "            def copy_data(m, i, o):\n",
    "                my_embedding.copy_(o.data)\n",
    "\n",
    "            h = self.extraction_layer.register_forward_hook(copy_data)\n",
    "            with torch.no_grad():\n",
    "                h_x = self.model(images)\n",
    "            h.remove()\n",
    "\n",
    "            if tensor:\n",
    "                return my_embedding\n",
    "            else:\n",
    "                if self.model_name in ['alexnet', 'vgg']:\n",
    "                    return my_embedding.numpy()[:, :]\n",
    "                elif self.model_name == 'densenet' or 'efficientnet' in self.model_name:\n",
    "                    return torch.mean(my_embedding, (2, 3), True).numpy()[:, :, 0, 0]\n",
    "                else:\n",
    "                    return my_embedding.numpy()[:, :, 0, 0]\n",
    "        else:\n",
    "            image = self.normalize(self.to_tensor(self.scaler(img))).unsqueeze(0).to(self.device)\n",
    "\n",
    "            if self.model_name in ['alexnet', 'vgg']:\n",
    "                my_embedding = torch.zeros(1, self.layer_output_size)\n",
    "            elif self.model_name == 'densenet' or 'efficientnet' in self.model_name:\n",
    "                my_embedding = torch.zeros(1, self.layer_output_size, 7, 7)\n",
    "            else:\n",
    "                my_embedding = torch.zeros(1, self.layer_output_size, 1, 1)\n",
    "\n",
    "            def copy_data(m, i, o):\n",
    "                my_embedding.copy_(o.data)\n",
    "\n",
    "            h = self.extraction_layer.register_forward_hook(copy_data)\n",
    "            with torch.no_grad():\n",
    "                h_x = self.model(image)\n",
    "            h.remove()\n",
    "\n",
    "            if tensor:\n",
    "                return my_embedding\n",
    "            else:\n",
    "                if self.model_name in ['alexnet', 'vgg']:\n",
    "                    return my_embedding.numpy()[0, :]\n",
    "                elif self.model_name == 'densenet':\n",
    "                    return torch.mean(my_embedding, (2, 3), True).numpy()[0, :, 0, 0]\n",
    "                else:\n",
    "                    return my_embedding.numpy()[0, :, 0, 0]\n",
    "\n",
    "    def _get_model_and_layer(self, model_name, layer):\n",
    "        if model_name.startswith('resnet') and not model_name.startswith('resnet-'):\n",
    "            model = getattr(models, model_name)(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model._modules.get('avgpool')\n",
    "                self.layer_output_size = self.RESNET_OUTPUT_SIZES[model_name]\n",
    "            else:\n",
    "                layer = model._modules.get(layer)\n",
    "            return model, layer\n",
    "        elif model_name == 'resnet-18':\n",
    "            model = models.resnet18(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model._modules.get('avgpool')\n",
    "                self.layer_output_size = 512\n",
    "            else:\n",
    "                layer = model._modules.get(layer)\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        elif model_name == 'alexnet':\n",
    "            model = models.alexnet(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model.classifier[-2]\n",
    "                self.layer_output_size = 4096\n",
    "            else:\n",
    "                layer = model.classifier[-layer]\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        elif model_name == 'vgg':\n",
    "            model = models.vgg11_bn(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model.classifier[-2]\n",
    "                self.layer_output_size = model.classifier[-1].in_features\n",
    "            else:\n",
    "                layer = model.classifier[-layer]\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        elif model_name == 'densenet':\n",
    "            model = models.densenet121(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model.features[-1]\n",
    "                self.layer_output_size = model.classifier.in_features\n",
    "            else:\n",
    "                raise KeyError('Un support %s for layer parameters' % model_name)\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        elif \"efficientnet\" in model_name:\n",
    "            if model_name == \"efficientnet_b0\":\n",
    "                model = models.efficientnet_b0(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b1\":\n",
    "                model = models.efficientnet_b1(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b2\":\n",
    "                model = models.efficientnet_b2(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b3\":\n",
    "                model = models.efficientnet_b3(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b4\":\n",
    "                model = models.efficientnet_b4(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b5\":\n",
    "                model = models.efficientnet_b5(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b6\":\n",
    "                model = models.efficientnet_b6(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b7\":\n",
    "                model = models.efficientnet_b7(pretrained=True)\n",
    "            else:\n",
    "                raise KeyError('Un support %s.' % model_name)\n",
    "\n",
    "            if layer == 'default':\n",
    "                layer = model.features\n",
    "                self.layer_output_size = self.EFFICIENTNET_OUTPUT_SIZES[model_name]\n",
    "            else:\n",
    "                raise KeyError('Un support %s for layer parameters' % model_name)\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        else:\n",
    "            raise KeyError('Model %s was not found' % model_name)\n",
    "\n",
    "def calculate_similarity(embeddings):\n",
    "    return cosine_similarity(embeddings)\n",
    "\n",
    "def evaluate_model(embeddings, labels, threshold):\n",
    "    correct_classifications = 0\n",
    "    incorrect_classifications = 0\n",
    "\n",
    "    for i, embedding in enumerate(embeddings):\n",
    "        similarities = []\n",
    "        for j in range(len(embeddings)):\n",
    "            if i != j:\n",
    "                sim = cosine_similarity([embedding], [embeddings[j]])[0][0]\n",
    "                similarities.append((sim, labels[j]))\n",
    "\n",
    "        # 유사도 기준으로 정렬\n",
    "        similarities.sort(reverse=True, key=lambda x: x[0])\n",
    "\n",
    "        # 분류 결과 확인\n",
    "        if similarities[0][0] > threshold and similarities[0][1] == labels[i]:\n",
    "            correct_classifications += 1\n",
    "        else:\n",
    "            incorrect_classifications += 1\n",
    "\n",
    "    return correct_classifications, incorrect_classifications\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    valid_image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']  # 허용된 이미지 파일 확장자 목록\n",
    "    for class_folder_name in os.listdir(folder):\n",
    "        class_folder_path = os.path.join(folder, class_folder_name)\n",
    "        if not os.path.isdir(class_folder_path):\n",
    "            continue\n",
    "        for filename in os.listdir(class_folder_path):\n",
    "            img_path = os.path.join(class_folder_path, filename)\n",
    "            if os.path.splitext(filename)[1].lower() in valid_image_extensions:  # 파일 확장자 확인\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "                images.append(img)\n",
    "                labels.append(class_folder_name)\n",
    "    return images, labels\n",
    "\n",
    "def main():\n",
    "    # 설정\n",
    "    model_names = ['resnet18', 'resnet50', 'efficientnet_b0', 'efficientnet_b7']\n",
    "    cuda = torch.cuda.is_available()\n",
    "    layer = 'default'\n",
    "    \n",
    "    # 폴더에서 이미지와 레이블 불러오기\n",
    "    folder_path = './data-gatter/train'\n",
    "    images, labels = load_images_from_folder(folder_path)\n",
    "    \n",
    "    # 각 클래스당 최소 2개 이상의 이미지가 필요\n",
    "    required_label_count = 2\n",
    "    # 각 카테고리별 이미지 수 확인\n",
    "    label_counts = {label: labels.count(label) for label in set(labels)}\n",
    "    \n",
    "    # 카테고리별 이미지 수가 충분한지 확인\n",
    "    if any(count < required_label_count for count in label_counts.values()):\n",
    "        print(\"각 클래스에는 최소 2개의 이미지가 필요합니다.\")\n",
    "        return\n",
    "\n",
    "    # 평가 결과 저장\n",
    "    results = {}\n",
    "    \n",
    "    for model_name in model_names:\n",
    "        print(f\"Evaluating model {model_name}\")\n",
    "        img2vec = Img2Vec(cuda=cuda, model=model_name, layer=layer)\n",
    "        \n",
    "        # 임베딩 추출\n",
    "        start_time = time.time()\n",
    "        embeddings = [img2vec.get_vec(img) for img in images]\n",
    "        embeddings = np.array(embeddings)\n",
    "        processing_time = (time.time() - start_time) / len(images)\n",
    "        \n",
    "        # 다양한 임계값에 대해 평가\n",
    "        best_threshold = 0\n",
    "        best_correct = 0\n",
    "        best_incorrect = len(images)\n",
    "        thresholds = np.arange(0.1, 1.0, 0.05)\n",
    "\n",
    "        for threshold in thresholds:\n",
    "            correct, incorrect = evaluate_model(embeddings, labels, threshold)\n",
    "            if correct > best_correct and incorrect < best_incorrect:\n",
    "                best_threshold = threshold\n",
    "                best_correct = correct\n",
    "                best_incorrect = incorrect\n",
    "\n",
    "        results[model_name] = {\n",
    "            'best_threshold': best_threshold,\n",
    "            'correct_classifications': best_correct,\n",
    "            'incorrect_classifications': best_incorrect,\n",
    "            'processing_time': processing_time\n",
    "        }\n",
    "        \n",
    "        print(f\"Model {model_name} - Best Threshold: {best_threshold}, Correct Classifications: {best_correct}, Incorrect Classifications: {best_incorrect}, Processing Time: {processing_time} per image\")\n",
    "    \n",
    "    # 결과 출력 또는 저장\n",
    "    for model_name, result in results.items():\n",
    "        print(f\"\\nModel: {model_name}\")\n",
    "        print(f\"Best Threshold: {result['best_threshold']}\")\n",
    "        print(f\"Correct Classifications: {result['correct_classifications']}\")\n",
    "        print(f\"Incorrect Classifications: {result['incorrect_classifications']}\")\n",
    "        print(f\"Processing Time per Image: {result['processing_time']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Nearest Neighbor 기반 평가\n",
    "### - 각 이미지에 대해 다른 모든 이미지와의 코사인 유사도 계산\n",
    "### - 유사도가 가장 높은 이미지 선택\n",
    "### - 선택한 이미지의 레이블이 현재 이미지의 레이블과 일치하는지 확인해 정확도 계산\n",
    "### - 새로운 이미지가 주어졌을 때 해당 이미지가 어떤 클래스로 분류될지를 시뮬레이션 하는 방식\n",
    "\n",
    "Model: resnet18\n",
    "Accuracy: 0.8611111111111112\n",
    "Correct Classifications: 31\n",
    "Incorrect Classifications: 5\n",
    "Processing Time per Image: 0.059573855664994985\n",
    "\n",
    "Model: resnet50\n",
    "Accuracy: 0.8333333333333334\n",
    "Correct Classifications: 30\n",
    "Incorrect Classifications: 6\n",
    "Processing Time per Image: 0.1250338355700175\n",
    "\n",
    "Model: efficientnet_b0\n",
    "Accuracy: 0.4444444444444444\n",
    "Correct Classifications: 16\n",
    "Incorrect Classifications: 20\n",
    "Processing Time per Image: 0.06705013910929362\n",
    "\n",
    "Model: efficientnet_b7\n",
    "Accuracy: 0.6388888888888888\n",
    "Correct Classifications: 23\n",
    "Incorrect Classifications: 13\n",
    "Processing Time per Image: 0.3125931951734755"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import certifi\n",
    "import os\n",
    "import ssl\n",
    "\n",
    "# SSL 인증서 설정\n",
    "os.environ['SSL_CERT_FILE'] = certifi.where()\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# 이미지를 벡터로 변환(임베딩)하는 역할 (이미지 ->> 벡터)\n",
    "class Img2Vec():\n",
    "    RESNET_OUTPUT_SIZES = {\n",
    "        'resnet18': 512,\n",
    "        'resnet34': 512,\n",
    "        'resnet50': 2048,\n",
    "        'resnet101': 2048,\n",
    "        'resnet152': 2048\n",
    "    }\n",
    "\n",
    "    EFFICIENTNET_OUTPUT_SIZES = {\n",
    "        'efficientnet_b0': 1280,\n",
    "        'efficientnet_b1': 1280,\n",
    "        'efficientnet_b2': 1408,\n",
    "        'efficientnet_b3': 1536,\n",
    "        'efficientnet_b4': 1792,\n",
    "        'efficientnet_b5': 2048,\n",
    "        'efficientnet_b6': 2304,\n",
    "        'efficientnet_b7': 2560\n",
    "    }\n",
    "\n",
    "    def __init__(self, cuda=False, model='resnet18', layer='default', layer_output_size=512, gpu=0):\n",
    "        self.device = torch.device(f\"cuda:{gpu}\" if cuda else \"cpu\")\n",
    "        self.layer_output_size = layer_output_size\n",
    "        self.model_name = model\n",
    "\n",
    "        self.model, self.extraction_layer = self._get_model_and_layer(model, layer)\n",
    "\n",
    "        self.model = self.model.to(self.device)\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "        self.scaler = transforms.Resize((224, 224))\n",
    "        self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                              std=[0.229, 0.224, 0.225])\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "\n",
    "    # 이미지를 입력으로 받아 벡터로 변환\n",
    "    def get_vec(self, img, tensor=False):\n",
    "        if type(img) == list:\n",
    "            a = [self.normalize(self.to_tensor(self.scaler(im))) for im in img]\n",
    "            images = torch.stack(a).to(self.device)\n",
    "            if self.model_name in ['alexnet', 'vgg']:\n",
    "                my_embedding = torch.zeros(len(img), self.layer_output_size)\n",
    "            elif self.model_name == 'densenet' or 'efficientnet' in self.model_name:\n",
    "                my_embedding = torch.zeros(len(img), self.layer_output_size, 7, 7)\n",
    "            else:\n",
    "                my_embedding = torch.zeros(len(img), self.layer_output_size, 1, 1)\n",
    "\n",
    "            def copy_data(m, i, o):\n",
    "                my_embedding.copy_(o.data)\n",
    "\n",
    "            h = self.extraction_layer.register_forward_hook(copy_data)\n",
    "            with torch.no_grad():\n",
    "                h_x = self.model(images)\n",
    "            h.remove()\n",
    "\n",
    "            if tensor:\n",
    "                return my_embedding\n",
    "            else:\n",
    "                if self.model_name in ['alexnet', 'vgg']:\n",
    "                    return my_embedding.numpy()[:, :]\n",
    "                elif self.model_name == 'densenet' or 'efficientnet' in self.model_name:\n",
    "                    return torch.mean(my_embedding, (2, 3), True).numpy()[:, :, 0, 0]\n",
    "                else:\n",
    "                    return my_embedding.numpy()[:, :, 0, 0]\n",
    "        else:\n",
    "            image = self.normalize(self.to_tensor(self.scaler(img))).unsqueeze(0).to(self.device)\n",
    "\n",
    "            if self.model_name in ['alexnet', 'vgg']:\n",
    "                my_embedding = torch.zeros(1, self.layer_output_size)\n",
    "            elif self.model_name == 'densenet' or 'efficientnet' in self.model_name:\n",
    "                my_embedding = torch.zeros(1, self.layer_output_size, 7, 7)\n",
    "            else:\n",
    "                my_embedding = torch.zeros(1, self.layer_output_size, 1, 1)\n",
    "\n",
    "            def copy_data(m, i, o):\n",
    "                my_embedding.copy_(o.data)\n",
    "\n",
    "            h = self.extraction_layer.register_forward_hook(copy_data)\n",
    "            with torch.no_grad():\n",
    "                h_x = self.model(image)\n",
    "            h.remove()\n",
    "\n",
    "            if tensor:\n",
    "                return my_embedding\n",
    "            else:\n",
    "                if self.model_name in ['alexnet', 'vgg']:\n",
    "                    return my_embedding.numpy()[0, :]\n",
    "                elif self.model_name == 'densenet':\n",
    "                    return torch.mean(my_embedding, (2, 3), True).numpy()[0, :, 0, 0]\n",
    "                else:\n",
    "                    return my_embedding.numpy()[0, :, 0, 0]\n",
    "\n",
    "    # 주어진 모델 이름에 따라 모델과 해당 레이어 가져옴\n",
    "    def _get_model_and_layer(self, model_name, layer):\n",
    "        if model_name.startswith('resnet') and not model_name.startswith('resnet-'):\n",
    "            model = getattr(models, model_name)(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model._modules.get('avgpool')\n",
    "                self.layer_output_size = self.RESNET_OUTPUT_SIZES[model_name]\n",
    "            else:\n",
    "                layer = model._modules.get(layer)\n",
    "            return model, layer\n",
    "        elif model_name == 'resnet-18':\n",
    "            model = models.resnet18(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model._modules.get('avgpool')\n",
    "                self.layer_output_size = 512\n",
    "            else:\n",
    "                layer = model._modules.get(layer)\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        elif model_name == 'alexnet':\n",
    "            model = models.alexnet(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model.classifier[-2]\n",
    "                self.layer_output_size = 4096\n",
    "            else:\n",
    "                layer = model.classifier[-layer]\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        elif model_name == 'vgg':\n",
    "            model = models.vgg11_bn(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model.classifier[-2]\n",
    "                self.layer_output_size = model.classifier[-1].in_features\n",
    "            else:\n",
    "                layer = model.classifier[-layer]\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        elif model_name == 'densenet':\n",
    "            model = models.densenet121(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model.features[-1]\n",
    "                self.layer_output_size = model.classifier.in_features\n",
    "            else:\n",
    "                raise KeyError('Un support %s for layer parameters' % model_name)\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        elif \"efficientnet\" in model_name:\n",
    "            if model_name == \"efficientnet_b0\":\n",
    "                model = models.efficientnet_b0(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b1\":\n",
    "                model = models.efficientnet_b1(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b2\":\n",
    "                model = models.efficientnet_b2(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b3\":\n",
    "                model = models.efficientnet_b3(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b4\":\n",
    "                model = models.efficientnet_b4(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b5\":\n",
    "                model = models.efficientnet_b5(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b6\":\n",
    "                model = models.efficientnet_b6(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b7\":\n",
    "                model = models.efficientnet_b7(pretrained=True)\n",
    "            else:\n",
    "                raise KeyError('Un support %s.' % model_name)\n",
    "\n",
    "            if layer == 'default':\n",
    "                layer = model.features\n",
    "                self.layer_output_size = self.EFFICIENTNET_OUTPUT_SIZES[model_name]\n",
    "            else:\n",
    "                raise KeyError('Un support %s for layer parameters' % model_name)\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        else:\n",
    "            raise KeyError('Model %s was not found' % model_name)\n",
    "\n",
    "# 주어진 임베딩(벡터)간의 코사인 유사도 계산 - 두 벡터가 얼마나 유사한지 측정\n",
    "def calculate_similarity(embeddings):\n",
    "    return cosine_similarity(embeddings)\n",
    "\n",
    "# 주어진 폴더에서 이미지 읽어오고, 이미지와 해당 레이블(폴더 이름) 반환\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    valid_image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']\n",
    "    for class_folder_name in os.listdir(folder):\n",
    "        class_folder_path = os.path.join(folder, class_folder_name)\n",
    "        if not os.path.isdir(class_folder_path):\n",
    "            continue\n",
    "        for filename in os.listdir(class_folder_path):\n",
    "            img_path = os.path.join(class_folder_path, filename)\n",
    "            if os.path.splitext(filename)[1].lower() in valid_image_extensions:\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "                images.append(img)\n",
    "                labels.append(class_folder_name)\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "def classify_images(model_names, folder_path, cuda=False):\n",
    "    # 이미지와 레이블 불러오기\n",
    "    images, labels = load_images_from_folder(folder_path)\n",
    "\n",
    "    results = {}\n",
    "    for model_name in model_names:\n",
    "        print(f\"Evaluating model {model_name}\")\n",
    "        # 모델 초기화\n",
    "        img2vec = Img2Vec(cuda=cuda, model=model_name)\n",
    "\n",
    "        # 임베딩 추출\n",
    "        start_time = time.time()\n",
    "        embeddings = [img2vec.get_vec(img) for img in images]\n",
    "        embeddings = np.array(embeddings)\n",
    "        processing_time = (time.time() - start_time) / len(images)\n",
    "\n",
    "        # 올바르게 분류된 데이터 수 및 분류되지 않은 데이터 수 계산\n",
    "        correct_classifications = 0\n",
    "        incorrect_classifications = 0\n",
    "\n",
    "        for i, embedding in enumerate(embeddings):\n",
    "            similarities = []\n",
    "            for j in range(len(images)):\n",
    "                if i != j:\n",
    "                    sim = cosine_similarity([embedding], [embeddings[j]])[0][0]\n",
    "                    similarities.append((sim, labels[j]))\n",
    "\n",
    "            # 유사도 기준으로 정렬\n",
    "            similarities.sort(reverse=True, key=lambda x: x[0])\n",
    "\n",
    "            # 가장 유사한 이미지와 해당 유사도 출력\n",
    "            most_similar_label = similarities[0][1]\n",
    "\n",
    "            # 분류 결과 확인\n",
    "            if most_similar_label == labels[i]:\n",
    "                correct_classifications += 1\n",
    "            else:\n",
    "                incorrect_classifications += 1\n",
    "\n",
    "        # 정확도 계산\n",
    "        total_images = correct_classifications + incorrect_classifications\n",
    "        accuracy = correct_classifications / total_images\n",
    "\n",
    "        results[model_name] = {\n",
    "            'accuracy': accuracy,\n",
    "            'correct_classifications': correct_classifications,\n",
    "            'incorrect_classifications': incorrect_classifications,\n",
    "            'processing_time': processing_time\n",
    "        }\n",
    "\n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    folder_path = './data-gatter/train'\n",
    "    model_names = ['resnet18', 'resnet50', 'efficientnet_b0', 'efficientnet_b7']\n",
    "    cuda = torch.cuda.is_available()\n",
    "\n",
    "    results = classify_images(model_names, folder_path, cuda)\n",
    "    for model_name, result in results.items():\n",
    "        print(f\"\\nModel: {model_name}\")\n",
    "        print(f\"Accuracy: {result['accuracy']}\")\n",
    "        print(f\"Correct Classifications: {result['correct_classifications']}\")\n",
    "        print(f\"Incorrect Classifications: {result['incorrect_classifications']}\")\n",
    "        print(f\"Processing Time per Image: {result['processing_time']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 새로운 이미지 데이터가 들어왔을 때, 유사도가 높은 상위 10개의 레퍼런스 이미지 중 가장 많이 존재하는 레이블로 할당하여 분류\n",
    "\n",
    "Model: resnet18\n",
    "Accuracy: 0.3333333333333333\n",
    "Correct Classifications: 2\n",
    "Incorrect Classifications: 4\n",
    "Predictions: ['DOT', 'DOT', 'BURR', 'BUBBLE', 'BOLD', 'DOT']\n",
    "\n",
    "Model: resnet50\n",
    "Accuracy: 0.5\n",
    "Correct Classifications: 3\n",
    "Incorrect Classifications: 3\n",
    "Predictions: ['DUST', 'DOT', 'BURR', 'BUBBLE', 'BOLD', 'DOT']\n",
    "\n",
    "Model: efficientnet_b0\n",
    "Accuracy: 0.0\n",
    "Correct Classifications: 0\n",
    "Incorrect Classifications: 6\n",
    "Predictions: ['DAMAGE', 'BOLD', 'BOLD', 'DUST', 'BURR', 'BURR']\n",
    "\n",
    "Model: efficientnet_b7\n",
    "Accuracy: 0.5\n",
    "Correct Classifications: 3\n",
    "Incorrect Classifications: 3\n",
    "Predictions: ['DUST', 'DOT', 'DOT', 'BUBBLE', 'BURR', 'DOT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import time\n",
    "from collections import Counter\n",
    "import certifi\n",
    "import os\n",
    "import ssl\n",
    "\n",
    "# SSL 인증서 설정\n",
    "os.environ['SSL_CERT_FILE'] = certifi.where()\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# 이미지를 벡터로 변환(임베딩)하는 역할 (이미지 ->> 벡터)\n",
    "class Img2Vec():\n",
    "    RESNET_OUTPUT_SIZES = {\n",
    "        'resnet18': 512,\n",
    "        'resnet34': 512,\n",
    "        'resnet50': 2048,\n",
    "        'resnet101': 2048,\n",
    "        'resnet152': 2048\n",
    "    }\n",
    "\n",
    "    EFFICIENTNET_OUTPUT_SIZES = {\n",
    "        'efficientnet_b0': 1280,\n",
    "        'efficientnet_b1': 1280,\n",
    "        'efficientnet_b2': 1408,\n",
    "        'efficientnet_b3': 1536,\n",
    "        'efficientnet_b4': 1792,\n",
    "        'efficientnet_b5': 2048,\n",
    "        'efficientnet_b6': 2304,\n",
    "        'efficientnet_b7': 2560\n",
    "    }\n",
    "\n",
    "    def __init__(self, cuda=False, model='resnet18', layer='default', layer_output_size=512, gpu=0):\n",
    "        self.device = torch.device(f\"cuda:{gpu}\" if cuda else \"cpu\")\n",
    "        self.layer_output_size = layer_output_size\n",
    "        self.model_name = model\n",
    "\n",
    "        self.model, self.extraction_layer = self._get_model_and_layer(model, layer)\n",
    "\n",
    "        self.model = self.model.to(self.device)\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "        self.scaler = transforms.Resize((224, 224))\n",
    "        self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                              std=[0.229, 0.224, 0.225])\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "\n",
    "    # 이미지를 입력으로 받아 벡터로 변환\n",
    "    def get_vec(self, img, tensor=False):\n",
    "        if type(img) == list:\n",
    "            a = [self.normalize(self.to_tensor(self.scaler(im))) for im in img]\n",
    "            images = torch.stack(a).to(self.device)\n",
    "            if self.model_name in ['alexnet', 'vgg']:\n",
    "                my_embedding = torch.zeros(len(img), self.layer_output_size)\n",
    "            elif self.model_name == 'densenet' or 'efficientnet' in self.model_name:\n",
    "                my_embedding = torch.zeros(len(img), self.layer_output_size, 7, 7)\n",
    "            else:\n",
    "                my_embedding = torch.zeros(len(img), self.layer_output_size, 1, 1)\n",
    "\n",
    "            def copy_data(m, i, o):\n",
    "                my_embedding.copy_(o.data)\n",
    "\n",
    "            h = self.extraction_layer.register_forward_hook(copy_data)\n",
    "            with torch.no_grad():\n",
    "                h_x = self.model(images)\n",
    "            h.remove()\n",
    "\n",
    "            if tensor:\n",
    "                return my_embedding\n",
    "            else:\n",
    "                if self.model_name in ['alexnet', 'vgg']:\n",
    "                    return my_embedding.numpy()[:, :]\n",
    "                elif self.model_name == 'densenet' or 'efficientnet' in self.model_name:\n",
    "                    return torch.mean(my_embedding, (2, 3), True).numpy()[:, :, 0, 0]\n",
    "                else:\n",
    "                    return my_embedding.numpy()[:, :, 0, 0]\n",
    "        else:\n",
    "            image = self.normalize(self.to_tensor(self.scaler(img))).unsqueeze(0).to(self.device)\n",
    "\n",
    "            if self.model_name in ['alexnet', 'vgg']:\n",
    "                my_embedding = torch.zeros(1, self.layer_output_size)\n",
    "            elif self.model_name == 'densenet' or 'efficientnet' in self.model_name:\n",
    "                my_embedding = torch.zeros(1, self.layer_output_size, 7, 7)\n",
    "            else:\n",
    "                my_embedding = torch.zeros(1, self.layer_output_size, 1, 1)\n",
    "\n",
    "            def copy_data(m, i, o):\n",
    "                my_embedding.copy_(o.data)\n",
    "\n",
    "            h = self.extraction_layer.register_forward_hook(copy_data)\n",
    "            with torch.no_grad():\n",
    "                h_x = self.model(image)\n",
    "            h.remove()\n",
    "\n",
    "            if tensor:\n",
    "                return my_embedding\n",
    "            else:\n",
    "                if self.model_name in ['alexnet', 'vgg']:\n",
    "                    return my_embedding.numpy()[0, :]\n",
    "                elif self.model_name == 'densenet':\n",
    "                    return torch.mean(my_embedding, (2, 3), True).numpy()[0, :, 0, 0]\n",
    "                else:\n",
    "                    return my_embedding.numpy()[0, :, 0, 0]\n",
    "\n",
    "    # 주어진 모델 이름에 따라 모델과 해당 레이어 가져옴\n",
    "    def _get_model_and_layer(self, model_name, layer):\n",
    "        if model_name.startswith('resnet') and not model_name.startswith('resnet-'):\n",
    "            model = getattr(models, model_name)(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model._modules.get('avgpool')\n",
    "                self.layer_output_size = self.RESNET_OUTPUT_SIZES[model_name]\n",
    "            else:\n",
    "                layer = model._modules.get(layer)\n",
    "            return model, layer\n",
    "        elif model_name == 'resnet-18':\n",
    "            model = models.resnet18(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model._modules.get('avgpool')\n",
    "                self.layer_output_size = 512\n",
    "            else:\n",
    "                layer = model._modules.get(layer)\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        elif model_name == 'alexnet':\n",
    "            model = models.alexnet(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model.classifier[-2]\n",
    "                self.layer_output_size = 4096\n",
    "            else:\n",
    "                layer = model.classifier[-layer]\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        elif model_name == 'vgg':\n",
    "            model = models.vgg11_bn(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model.classifier[-2]\n",
    "                self.layer_output_size = model.classifier[-1].in_features\n",
    "            else:\n",
    "                layer = model.classifier[-layer]\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        elif model_name == 'densenet':\n",
    "            model = models.densenet121(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model.features[-1]\n",
    "                self.layer_output_size = model.classifier.in_features\n",
    "            else:\n",
    "                raise KeyError('Un support %s for layer parameters' % model_name)\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        elif \"efficientnet\" in model_name:\n",
    "            if model_name == \"efficientnet_b0\":\n",
    "                model = models.efficientnet_b0(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b1\":\n",
    "                model = models.efficientnet_b1(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b2\":\n",
    "                model = models.efficientnet_b2(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b3\":\n",
    "                model = models.efficientnet_b3(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b4\":\n",
    "                model = models.efficientnet_b4(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b5\":\n",
    "                model = models.efficientnet_b5(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b6\":\n",
    "                model = models.efficientnet_b6(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b7\":\n",
    "                model = models.efficientnet_b7(pretrained=True)\n",
    "            else:\n",
    "                raise KeyError('Un support %s.' % model_name)\n",
    "\n",
    "            if layer == 'default':\n",
    "                layer = model.features\n",
    "                self.layer_output_size = self.EFFICIENTNET_OUTPUT_SIZES[model_name]\n",
    "            else:\n",
    "                raise KeyError('Un support %s for layer parameters' % model_name)\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        else:\n",
    "            raise KeyError('Model %s was not found' % model_name)\n",
    "\n",
    "# 주어진 임베딩(벡터)간의 코사인 유사도 계산 - 두 벡터가 얼마나 유사한지 측정\n",
    "def calculate_similarity(embeddings):\n",
    "    return cosine_similarity(embeddings)\n",
    "\n",
    "# 주어진 폴더에서 이미지 읽어오고, 이미지와 해당 레이블(폴더 이름) 반환\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    valid_image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']\n",
    "    for class_folder_name in os.listdir(folder):\n",
    "        class_folder_path = os.path.join(folder, class_folder_name)\n",
    "        if not os.path.isdir(class_folder_path):\n",
    "            continue\n",
    "        for filename in os.listdir(class_folder_path):\n",
    "            img_path = os.path.join(class_folder_path, filename)\n",
    "            if os.path.splitext(filename)[1].lower() in valid_image_extensions:\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "                images.append(img)\n",
    "                labels.append(class_folder_name)\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "def classify_images(model_names, reference_folder, new_folder, cuda=False):\n",
    "    # 레퍼런스 이미지와 레이블 불러오기\n",
    "    ref_images, ref_labels = load_images_from_folder(reference_folder)\n",
    "    \n",
    "    # 새로운 이미지와 레이블 불러오기\n",
    "    new_images, new_labels = load_images_from_folder(new_folder)\n",
    "\n",
    "    results = {}\n",
    "    for model_name in model_names:\n",
    "        print(f\"Evaluating model {model_name}\")\n",
    "        # 모델 초기화\n",
    "        img2vec = Img2Vec(cuda=cuda, model=model_name)\n",
    "\n",
    "        # 레퍼런스 임베딩 추출\n",
    "        ref_embeddings = [img2vec.get_vec(img) for img in ref_images]\n",
    "        ref_embeddings = np.array(ref_embeddings)\n",
    "\n",
    "        correct_classifications = 0\n",
    "        incorrect_classifications = 0\n",
    "        predictions = []\n",
    "\n",
    "        for i, new_image in enumerate(new_images):\n",
    "            new_embedding = img2vec.get_vec(new_image)\n",
    "            similarities = []\n",
    "\n",
    "            for j in range(len(ref_images)):\n",
    "                sim = cosine_similarity([new_embedding], [ref_embeddings[j]])[0][0]\n",
    "                similarities.append((sim, ref_labels[j]))\n",
    "\n",
    "            # 유사도 기준으로 정렬 후 상위 10개 선택\n",
    "            similarities.sort(reverse=True, key=lambda x: x[0])\n",
    "            top_10_similarities = similarities[:10]\n",
    "\n",
    "            # 가장 많이 등장하는 레이블 선택\n",
    "            top_10_labels = [label for _, label in top_10_similarities]\n",
    "            predicted_label = Counter(top_10_labels).most_common(1)[0][0]\n",
    "            predictions.append((predicted_label, new_labels[i]))\n",
    "\n",
    "            # 분류 결과 확인\n",
    "            if predicted_label == new_labels[i]:\n",
    "                correct_classifications += 1\n",
    "            else:\n",
    "                incorrect_classifications += 1\n",
    "\n",
    "        # 정확도 계산\n",
    "        total_images = correct_classifications + incorrect_classifications\n",
    "        accuracy = correct_classifications / total_images\n",
    "\n",
    "        results[model_name] = {\n",
    "            'accuracy': accuracy,\n",
    "            'correct_classifications': correct_classifications,\n",
    "            'incorrect_classifications': incorrect_classifications,\n",
    "            'predictions': predictions\n",
    "        }\n",
    "\n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    reference_folder = './data-gatter/train'\n",
    "    new_folder = './data-gatter/test'\n",
    "    model_names = ['resnet18', 'resnet50', 'efficientnet_b0', 'efficientnet_b7']\n",
    "    cuda = torch.cuda.is_available()\n",
    "\n",
    "    results = classify_images(model_names, reference_folder, new_folder, cuda)\n",
    "    for model_name, result in results.items():\n",
    "        print(f\"\\nModel: {model_name}\")\n",
    "        print(f\"Accuracy: {result['accuracy']}\")\n",
    "        print(f\"Correct Classifications: {result['correct_classifications']}\")\n",
    "        print(f\"Incorrect Classifications: {result['incorrect_classifications']}\")\n",
    "        print(f\"Predictions:\")\n",
    "        for pred, true_label in result['predictions']:\n",
    "            print(f\"Predicted: {pred}, Actual: {true_label}\")"
   ]
  },
  {
   "attachments": {
    "Figure_1.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Threshold 기반 평가 \n",
    "### - 모든 이미지 간의 코사인 유사도 계산\n",
    "### - 동일한 레이블 가진 이미지 쌍의 유사도가 주어진 임계값보다 높은지, 다른 레이블을 사진 이미지 쌍의 유사도가 임계값 이하인지를 기준으로 정확도 평가\n",
    "\n",
    "![Figure_1.png](attachment:Figure_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating model resnet18\n",
    "Model: resnet18, Threshold: 0.1, Accuracy: 0.14285714285714285\n",
    "Model: resnet18, Threshold: 0.2, Accuracy: 0.14285714285714285\n",
    "Model: resnet18, Threshold: 0.30000000000000004, Accuracy: 0.14285714285714285\n",
    "Model: resnet18, Threshold: 0.4, Accuracy: 0.14285714285714285\n",
    "Model: resnet18, Threshold: 0.5, Accuracy: 0.14285714285714285\n",
    "Model: resnet18, Threshold: 0.6, Accuracy: 0.25873015873015875\n",
    "Model: resnet18, Threshold: 0.7000000000000001, Accuracy: 0.6555555555555556\n",
    "Model: resnet18, Threshold: 0.8, Accuracy: 0.8587301587301587\n",
    "Model: resnet18, Threshold: 0.9, Accuracy: 0.8666666666666667\n",
    "\n",
    "Evaluating model resnet50\n",
    "Model: resnet50, Threshold: 0.1, Accuracy: 0.14285714285714285\n",
    "Model: resnet50, Threshold: 0.2, Accuracy: 0.14285714285714285\n",
    "Model: resnet50, Threshold: 0.30000000000000004, Accuracy: 0.14285714285714285\n",
    "Model: resnet50, Threshold: 0.4, Accuracy: 0.14285714285714285\n",
    "Model: resnet50, Threshold: 0.5, Accuracy: 0.14285714285714285\n",
    "Model: resnet50, Threshold: 0.6, Accuracy: 0.15873015873015872\n",
    "Model: resnet50, Threshold: 0.7000000000000001, Accuracy: 0.49047619047619045\n",
    "Model: resnet50, Threshold: 0.8, Accuracy: 0.8174603174603174\n",
    "Model: resnet50, Threshold: 0.9, Accuracy: 0.8761904761904762\n",
    "\n",
    "Evaluating model efficientnet_b0\n",
    "Model: efficientnet_b0, Threshold: 0.1, Accuracy: 0.49523809523809526\n",
    "Model: efficientnet_b0, Threshold: 0.2, Accuracy: 0.580952380952381\n",
    "Model: efficientnet_b0, Threshold: 0.30000000000000004, Accuracy: 0.6349206349206349\n",
    "Model: efficientnet_b0, Threshold: 0.4, Accuracy: 0.707936507936508\n",
    "Model: efficientnet_b0, Threshold: 0.5, Accuracy: 0.7507936507936508\n",
    "Model: efficientnet_b0, Threshold: 0.6, Accuracy: 0.7777777777777778\n",
    "Model: efficientnet_b0, Threshold: 0.7000000000000001, Accuracy: 0.7777777777777778\n",
    "Model: efficientnet_b0, Threshold: 0.8, Accuracy: 0.792063492063492\n",
    "Model: efficientnet_b0, Threshold: 0.9, Accuracy: 0.8333333333333334\n",
    "\n",
    "Evaluating model efficientnet_b7\n",
    "Model: efficientnet_b7, Threshold: 0.1, Accuracy: 0.15714285714285714\n",
    "Model: efficientnet_b7, Threshold: 0.2, Accuracy: 0.15396825396825398\n",
    "Model: efficientnet_b7, Threshold: 0.30000000000000004, Accuracy: 0.1619047619047619\n",
    "Model: efficientnet_b7, Threshold: 0.4, Accuracy: 0.1984126984126984\n",
    "Model: efficientnet_b7, Threshold: 0.5, Accuracy: 0.2857142857142857\n",
    "Model: efficientnet_b7, Threshold: 0.6, Accuracy: 0.473015873015873\n",
    "Model: efficientnet_b7, Threshold: 0.7000000000000001, Accuracy: 0.6301587301587301\n",
    "Model: efficientnet_b7, Threshold: 0.8, Accuracy: 0.7841269841269841\n",
    "Model: efficientnet_b7, Threshold: 0.9, Accuracy: 0.8587301587301587"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import certifi\n",
    "import os\n",
    "import ssl\n",
    "\n",
    "# SSL 인증서 설정\n",
    "os.environ['SSL_CERT_FILE'] = certifi.where()\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# 이미지를 벡터로 변환(임베딩)하는 역할 (이미지 ->> 벡터)\n",
    "class Img2Vec():\n",
    "    RESNET_OUTPUT_SIZES = {\n",
    "        'resnet18': 512,\n",
    "        'resnet34': 512,\n",
    "        'resnet50': 2048,\n",
    "        'resnet101': 2048,\n",
    "        'resnet152': 2048\n",
    "    }\n",
    "\n",
    "    EFFICIENTNET_OUTPUT_SIZES = {\n",
    "        'efficientnet_b0': 1280,\n",
    "        'efficientnet_b1': 1280,\n",
    "        'efficientnet_b2': 1408,\n",
    "        'efficientnet_b3': 1536,\n",
    "        'efficientnet_b4': 1792,\n",
    "        'efficientnet_b5': 2048,\n",
    "        'efficientnet_b6': 2304,\n",
    "        'efficientnet_b7': 2560\n",
    "    }\n",
    "\n",
    "    def __init__(self, cuda=False, model='resnet18', layer='default', layer_output_size=512, gpu=0):\n",
    "        self.device = torch.device(f\"cuda:{gpu}\" if cuda else \"cpu\")\n",
    "        self.layer_output_size = layer_output_size\n",
    "        self.model_name = model\n",
    "\n",
    "        self.model, self.extraction_layer = self._get_model_and_layer(model, layer)\n",
    "\n",
    "        self.model = self.model.to(self.device)\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "        self.scaler = transforms.Resize((224, 224))\n",
    "        self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                              std=[0.229, 0.224, 0.225])\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "\n",
    "    # 이미지를 입력으로 받아 벡터로 변환\n",
    "    def get_vec(self, img, tensor=False):\n",
    "        if type(img) == list:\n",
    "            a = [self.normalize(self.to_tensor(self.scaler(im))) for im in img]\n",
    "            images = torch.stack(a).to(self.device)\n",
    "            if self.model_name in ['alexnet', 'vgg']:\n",
    "                my_embedding = torch.zeros(len(img), self.layer_output_size)\n",
    "            elif self.model_name == 'densenet' or 'efficientnet' in self.model_name:\n",
    "                my_embedding = torch.zeros(len(img), self.layer_output_size, 7, 7)\n",
    "            else:\n",
    "                my_embedding = torch.zeros(len(img), self.layer_output_size, 1, 1)\n",
    "\n",
    "            def copy_data(m, i, o):\n",
    "                my_embedding.copy_(o.data)\n",
    "\n",
    "            h = self.extraction_layer.register_forward_hook(copy_data)\n",
    "            with torch.no_grad():\n",
    "                h_x = self.model(images)\n",
    "            h.remove()\n",
    "\n",
    "            if tensor:\n",
    "                return my_embedding\n",
    "            else:\n",
    "                if self.model_name in ['alexnet', 'vgg']:\n",
    "                    return my_embedding.numpy()[:, :]\n",
    "                elif self.model_name == 'densenet' or 'efficientnet' in self.model_name:\n",
    "                    return torch.mean(my_embedding, (2, 3), True).numpy()[:, :, 0, 0]\n",
    "                else:\n",
    "                    return my_embedding.numpy()[:, :, 0, 0]\n",
    "        else:\n",
    "            image = self.normalize(self.to_tensor(self.scaler(img))).unsqueeze(0).to(self.device)\n",
    "\n",
    "            if self.model_name in ['alexnet', 'vgg']:\n",
    "                my_embedding = torch.zeros(1, self.layer_output_size)\n",
    "            elif self.model_name == 'densenet' or 'efficientnet' in self.model_name:\n",
    "                my_embedding = torch.zeros(1, self.layer_output_size, 7, 7)\n",
    "            else:\n",
    "                my_embedding = torch.zeros(1, self.layer_output_size, 1, 1)\n",
    "\n",
    "            def copy_data(m, i, o):\n",
    "                my_embedding.copy_(o.data)\n",
    "\n",
    "            h = self.extraction_layer.register_forward_hook(copy_data)\n",
    "            with torch.no_grad():\n",
    "                h_x = self.model(image)\n",
    "            h.remove()\n",
    "\n",
    "            if tensor:\n",
    "                return my_embedding\n",
    "            else:\n",
    "                if self.model_name in ['alexnet', 'vgg']:\n",
    "                    return my_embedding.numpy()[0, :]\n",
    "                elif self.model_name == 'densenet':\n",
    "                    return torch.mean(my_embedding, (2, 3), True).numpy()[0, :, 0, 0]\n",
    "                else:\n",
    "                    return my_embedding.numpy()[0, :, 0, 0]\n",
    "\n",
    "    # 주어진 모델 이름에 따라 모델과 해당 레이어 가져옴\n",
    "    def _get_model_and_layer(self, model_name, layer):\n",
    "        if model_name.startswith('resnet') and not model_name.startswith('resnet-'):\n",
    "            model = getattr(models, model_name)(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model._modules.get('avgpool')\n",
    "                self.layer_output_size = self.RESNET_OUTPUT_SIZES[model_name]\n",
    "            else:\n",
    "                layer = model._modules.get(layer)\n",
    "            return model, layer\n",
    "        elif model_name == 'resnet-18':\n",
    "            model = models.resnet18(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model._modules.get('avgpool')\n",
    "                self.layer_output_size = 512\n",
    "            else:\n",
    "                layer = model._modules.get(layer)\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        elif model_name == 'alexnet':\n",
    "            model = models.alexnet(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model.classifier[-2]\n",
    "                self.layer_output_size = 4096\n",
    "            else:\n",
    "                layer = model.classifier[-layer]\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        elif model_name == 'vgg':\n",
    "            model = models.vgg11_bn(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model.classifier[-2]\n",
    "                self.layer_output_size = model.classifier[-1].in_features\n",
    "            else:\n",
    "                layer = model.classifier[-layer]\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        elif model_name == 'densenet':\n",
    "            model = models.densenet121(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model.features[-1]\n",
    "                self.layer_output_size = model.classifier.in_features\n",
    "            else:\n",
    "                raise KeyError('Un support %s for layer parameters' % model_name)\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        elif \"efficientnet\" in model_name:\n",
    "            if model_name == \"efficientnet_b0\":\n",
    "                model = models.efficientnet_b0(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b1\":\n",
    "                model = models.efficientnet_b1(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b2\":\n",
    "                model = models.efficientnet_b2(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b3\":\n",
    "                model = models.efficientnet_b3(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b4\":\n",
    "                model = models.efficientnet_b4(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b5\":\n",
    "                model = models.efficientnet_b5(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b6\":\n",
    "                model = models.efficientnet_b6(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b7\":\n",
    "                model = models.efficientnet_b7(pretrained=True)\n",
    "            else:\n",
    "                raise KeyError('Un support %s.' % model_name)\n",
    "\n",
    "            if layer == 'default':\n",
    "                layer = model.features\n",
    "                self.layer_output_size = self.EFFICIENTNET_OUTPUT_SIZES[model_name]\n",
    "            else:\n",
    "                raise KeyError('Un support %s for layer parameters' % model_name)\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        else:\n",
    "            raise KeyError('Model %s was not found' % model_name)\n",
    "\n",
    "# 주어진 임베딩(벡터)간의 코사인 유사도 계산 - 두 벡터가 얼마나 유사한지 측정\n",
    "def calculate_similarity(embeddings):\n",
    "    return cosine_similarity(embeddings)\n",
    "\n",
    "# 주어진 임베딩(벡터)와 레이블 사용해 모델의 정확도 평가 - 유사도 임계값을 기준으로 올바르게 분류된 쌍의 비율을 계산\n",
    "\n",
    "def evaluate_model(embeddings, labels, thresholds):\n",
    "    results = []\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        class_similarities = defaultdict(list)\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for i in range(len(embeddings)):\n",
    "            for j in range(i + 1, len(embeddings)):\n",
    "                sim = cosine_similarity([embeddings[i]], [embeddings[j]])[0][0]\n",
    "                if labels[i] == labels[j]:\n",
    "                    class_similarities[labels[i]].append(sim)\n",
    "                    if sim > threshold:\n",
    "                        correct += 1\n",
    "                else:\n",
    "                    if sim <= threshold:\n",
    "                        correct += 1\n",
    "                total += 1\n",
    "\n",
    "        accuracy = correct / total\n",
    "        results.append((threshold, accuracy))\n",
    "    return results\n",
    "\n",
    "# 주어진 폴더에서 이미지 읽어오고, 이미지와 해당 레이블(폴더 이름) 반환\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    valid_image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']  # 허용된 이미지 파일 확장자 목록\n",
    "    for class_folder_name in os.listdir(folder):\n",
    "        class_folder_path = os.path.join(folder, class_folder_name)\n",
    "        if not os.path.isdir(class_folder_path):\n",
    "            continue\n",
    "        for filename in os.listdir(class_folder_path):\n",
    "            img_path = os.path.join(class_folder_path, filename)\n",
    "            if os.path.splitext(filename)[1].lower() in valid_image_extensions:  # 파일 확장자 확인\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "                images.append(img)\n",
    "                labels.append(class_folder_name)\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "def plot_results(results, model_name):\n",
    "    thresholds = [r[0] for r in results]\n",
    "    accuracies = [r[1] for r in results]\n",
    "\n",
    "    plt.plot(thresholds, accuracies, marker='o', label=model_name)\n",
    "\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy vs. Threshold')\n",
    "    plt.grid(True)\n",
    "\n",
    "def main_evaluation():\n",
    "    # 설정\n",
    "    model_names = ['resnet18', 'resnet50', 'efficientnet_b0', 'efficientnet_b7']\n",
    "    folder_path = './data-gatter/train'\n",
    "    cuda = torch.cuda.is_available()\n",
    "    thresholds = np.arange(0.1, 1.0, 0.1)  # 다양한 임계값 설정\n",
    "\n",
    "    # 이미지와 레이블 불러오기\n",
    "    images, labels = load_images_from_folder(folder_path)\n",
    "\n",
    "    results_all_models = {}\n",
    "    \n",
    "    for model_name in model_names:\n",
    "        print(f\"Evaluating model {model_name}\")\n",
    "        # 모델 초기화\n",
    "        img2vec = Img2Vec(cuda=cuda, model=model_name)\n",
    "\n",
    "        # 임베딩 추출\n",
    "        embeddings = [img2vec.get_vec(img) for img in images]\n",
    "        embeddings = np.array(embeddings)\n",
    "\n",
    "        # 성능 평가\n",
    "        results = evaluate_model(embeddings, labels, thresholds)\n",
    "        results_all_models[model_name] = results\n",
    "        \n",
    "        # 결과 출력\n",
    "        for threshold, accuracy in results:\n",
    "            print(f\"Model: {model_name}, Threshold: {threshold}, Accuracy: {accuracy}\")\n",
    "        \n",
    "        # 결과 그래프로 표시\n",
    "        plot_results(results, model_name)\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_evaluation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 새 이미지와 기존 레퍼런스 이미지 간의 유사도 계산\n",
    "- Threshold가 낮을수록 더 많은 이미지를 높은 유사도로 분류하지만, 잘못된 분류도 함께 증가할 수 있습니다.\n",
    "- 주어진 예시에서, 낮은 threshold (0.1)에서 많은 이미지들이 잘못된 레이블로 분류되었습니다.\n",
    "- Threshold 값을 높이면 유사도가 높은 경우에만 분류되기 때문에, 잘못된 분류가 줄어들 수 있지만, 너무 높으면 \"Unknown\"으로 분류되는 경우가 많아질 수 있습니다.\n",
    "\n",
    "Model: resnet18\n",
    "Threshold: 0.1\n",
    "Accuracy: 0.3333333333333333\n",
    "Correct Classifications: 2\n",
    "Incorrect Classifications: 4\n",
    "New Image 1: Actual Label: DUST, Predicted Label: BUBBLE, Similarity: 0.9488675594329834\n",
    "New Image 2: Actual Label: BURR, Predicted Label: DOT, Similarity: 0.8687189817428589\n",
    "New Image 3: Actual Label: DOT, Predicted Label: BURR, Similarity: 0.8907590508460999\n",
    "New Image 4: Actual Label: BUBBLE, Predicted Label: BUBBLE, Similarity: 0.8769079446792603\n",
    "New Image 5: Actual Label: BOLD, Predicted Label: BOLD, Similarity: 0.9077326059341431\n",
    "New Image 6: Actual Label: DAMAGE, Predicted Label: DOT, Similarity: 0.8365391492843628\n",
    "\n",
    "Model: resnet18\n",
    "Threshold: 0.2\n",
    "Accuracy: 0.3333333333333333\n",
    "Correct Classifications: 2\n",
    "Incorrect Classifications: 4\n",
    "New Image 1: Actual Label: DUST, Predicted Label: BUBBLE, Similarity: 0.9488675594329834\n",
    "New Image 2: Actual Label: BURR, Predicted Label: DOT, Similarity: 0.8687189817428589\n",
    "New Image 3: Actual Label: DOT, Predicted Label: BURR, Similarity: 0.8907590508460999\n",
    "New Image 4: Actual Label: BUBBLE, Predicted Label: BUBBLE, Similarity: 0.8769079446792603\n",
    "New Image 5: Actual Label: BOLD, Predicted Label: BOLD, Similarity: 0.9077326059341431\n",
    "New Image 6: Actual Label: DAMAGE, Predicted Label: DOT, Similarity: 0.8365391492843628\n",
    "\n",
    "Model: resnet18\n",
    "Threshold: 0.30000000000000004\n",
    "Accuracy: 0.3333333333333333\n",
    "Correct Classifications: 2\n",
    "Incorrect Classifications: 4\n",
    "New Image 1: Actual Label: DUST, Predicted Label: BUBBLE, Similarity: 0.9488675594329834\n",
    "New Image 2: Actual Label: BURR, Predicted Label: DOT, Similarity: 0.8687189817428589\n",
    "New Image 3: Actual Label: DOT, Predicted Label: BURR, Similarity: 0.8907590508460999\n",
    "New Image 4: Actual Label: BUBBLE, Predicted Label: BUBBLE, Similarity: 0.8769079446792603\n",
    "New Image 5: Actual Label: BOLD, Predicted Label: BOLD, Similarity: 0.9077326059341431\n",
    "New Image 6: Actual Label: DAMAGE, Predicted Label: DOT, Similarity: 0.8365391492843628\n",
    "\n",
    "Model: resnet18\n",
    "Threshold: 0.4\n",
    "Accuracy: 0.3333333333333333\n",
    "Correct Classifications: 2\n",
    "Incorrect Classifications: 4\n",
    "New Image 1: Actual Label: DUST, Predicted Label: BUBBLE, Similarity: 0.9488675594329834\n",
    "New Image 2: Actual Label: BURR, Predicted Label: DOT, Similarity: 0.8687189817428589\n",
    "New Image 3: Actual Label: DOT, Predicted Label: BURR, Similarity: 0.8907590508460999\n",
    "New Image 4: Actual Label: BUBBLE, Predicted Label: BUBBLE, Similarity: 0.8769079446792603\n",
    "New Image 5: Actual Label: BOLD, Predicted Label: BOLD, Similarity: 0.9077326059341431\n",
    "New Image 6: Actual Label: DAMAGE, Predicted Label: DOT, Similarity: 0.8365391492843628\n",
    "\n",
    "Model: resnet18\n",
    "Threshold: 0.5\n",
    "Accuracy: 0.3333333333333333\n",
    "Correct Classifications: 2\n",
    "Incorrect Classifications: 4\n",
    "New Image 1: Actual Label: DUST, Predicted Label: BUBBLE, Similarity: 0.9488675594329834\n",
    "New Image 2: Actual Label: BURR, Predicted Label: DOT, Similarity: 0.8687189817428589\n",
    "New Image 3: Actual Label: DOT, Predicted Label: BURR, Similarity: 0.8907590508460999\n",
    "New Image 4: Actual Label: BUBBLE, Predicted Label: BUBBLE, Similarity: 0.8769079446792603\n",
    "New Image 5: Actual Label: BOLD, Predicted Label: BOLD, Similarity: 0.9077326059341431\n",
    "New Image 6: Actual Label: DAMAGE, Predicted Label: DOT, Similarity: 0.8365391492843628\n",
    "\n",
    "Model: resnet18\n",
    "Threshold: 0.6\n",
    "Accuracy: 0.3333333333333333\n",
    "Correct Classifications: 2\n",
    "Incorrect Classifications: 4\n",
    "New Image 1: Actual Label: DUST, Predicted Label: BUBBLE, Similarity: 0.9488675594329834\n",
    "New Image 2: Actual Label: BURR, Predicted Label: DOT, Similarity: 0.8687189817428589\n",
    "New Image 3: Actual Label: DOT, Predicted Label: BURR, Similarity: 0.8907590508460999\n",
    "New Image 4: Actual Label: BUBBLE, Predicted Label: BUBBLE, Similarity: 0.8769079446792603\n",
    "New Image 5: Actual Label: BOLD, Predicted Label: BOLD, Similarity: 0.9077326059341431\n",
    "New Image 6: Actual Label: DAMAGE, Predicted Label: DOT, Similarity: 0.8365391492843628\n",
    "\n",
    "Model: resnet18\n",
    "Threshold: 0.7000000000000001\n",
    "Accuracy: 0.3333333333333333\n",
    "Correct Classifications: 2\n",
    "Incorrect Classifications: 4\n",
    "New Image 1: Actual Label: DUST, Predicted Label: BUBBLE, Similarity: 0.9488675594329834\n",
    "New Image 2: Actual Label: BURR, Predicted Label: DOT, Similarity: 0.8687189817428589\n",
    "New Image 3: Actual Label: DOT, Predicted Label: BURR, Similarity: 0.8907590508460999\n",
    "New Image 4: Actual Label: BUBBLE, Predicted Label: BUBBLE, Similarity: 0.8769079446792603\n",
    "New Image 5: Actual Label: BOLD, Predicted Label: BOLD, Similarity: 0.9077326059341431\n",
    "New Image 6: Actual Label: DAMAGE, Predicted Label: DOT, Similarity: 0.8365391492843628\n",
    "\n",
    "Model: resnet18\n",
    "Threshold: 0.8\n",
    "Accuracy: 0.3333333333333333\n",
    "Correct Classifications: 2\n",
    "Incorrect Classifications: 4\n",
    "New Image 1: Actual Label: DUST, Predicted Label: BUBBLE, Similarity: 0.9488675594329834\n",
    "New Image 2: Actual Label: BURR, Predicted Label: Unknown, Similarity: N/A\n",
    "New Image 3: Actual Label: DOT, Predicted Label: Unknown, Similarity: N/A\n",
    "New Image 4: Actual Label: BUBBLE, Predicted Label: Unknown, Similarity: N/A\n",
    "New Image 5: Actual Label: BOLD, Predicted Label: BOLD, Similarity: 0.9077326059341431\n",
    "New Image 6: Actual Label: DAMAGE, Predicted Label: Unknown, Similarity: N/A\n",
    "\n",
    "Model: resnet18\n",
    "Threshold: 0.9\n",
    "Accuracy: 0.16666666666666666\n",
    "Correct Classifications: 1\n",
    "Incorrect Classifications: 5\n",
    "(venv) hahyeonji@hahyeonjiui-MacBookPro ImageImbedding % \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import certifi\n",
    "import os\n",
    "import ssl\n",
    "\n",
    "# SSL 인증서 설정\n",
    "os.environ['SSL_CERT_FILE'] = certifi.where()\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# 이미지를 벡터로 변환(임베딩)하는 역할 (이미지 ->> 벡터)\n",
    "class Img2Vec():\n",
    "    RESNET_OUTPUT_SIZES = {\n",
    "        'resnet18': 512,\n",
    "        'resnet34': 512,\n",
    "        'resnet50': 2048,\n",
    "        'resnet101': 2048,\n",
    "        'resnet152': 2048\n",
    "    }\n",
    "\n",
    "    EFFICIENTNET_OUTPUT_SIZES = {\n",
    "        'efficientnet_b0': 1280,\n",
    "        'efficientnet_b1': 1280,\n",
    "        'efficientnet_b2': 1408,\n",
    "        'efficientnet_b3': 1536,\n",
    "        'efficientnet_b4': 1792,\n",
    "        'efficientnet_b5': 2048,\n",
    "        'efficientnet_b6': 2304,\n",
    "        'efficientnet_b7': 2560\n",
    "    }\n",
    "\n",
    "    def __init__(self, cuda=False, model='resnet18', layer='default', layer_output_size=512, gpu=0):\n",
    "        self.device = torch.device(f\"cuda:{gpu}\" if cuda else \"cpu\")\n",
    "        self.layer_output_size = layer_output_size\n",
    "        self.model_name = model\n",
    "\n",
    "        self.model, self.extraction_layer = self._get_model_and_layer(model, layer)\n",
    "\n",
    "        self.model = self.model.to(self.device)\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "        self.scaler = transforms.Resize((224, 224))\n",
    "        self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                              std=[0.229, 0.224, 0.225])\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "\n",
    "    # 이미지를 입력으로 받아 벡터로 변환\n",
    "    def get_vec(self, img, tensor=False):\n",
    "        if type(img) == list:\n",
    "            a = [self.normalize(self.to_tensor(self.scaler(im))) for im in img]\n",
    "            images = torch.stack(a).to(self.device)\n",
    "            if self.model_name in ['alexnet', 'vgg']:\n",
    "                my_embedding = torch.zeros(len(img), self.layer_output_size)\n",
    "            elif self.model_name == 'densenet' or 'efficientnet' in self.model_name:\n",
    "                my_embedding = torch.zeros(len(img), self.layer_output_size, 7, 7)\n",
    "            else:\n",
    "                my_embedding = torch.zeros(len(img), self.layer_output_size, 1, 1)\n",
    "\n",
    "            def copy_data(m, i, o):\n",
    "                my_embedding.copy_(o.data)\n",
    "\n",
    "            h = self.extraction_layer.register_forward_hook(copy_data)\n",
    "            with torch.no_grad():\n",
    "                h_x = self.model(images)\n",
    "            h.remove()\n",
    "\n",
    "            if tensor:\n",
    "                return my_embedding\n",
    "            else:\n",
    "                if self.model_name in ['alexnet', 'vgg']:\n",
    "                    return my_embedding.numpy()[:, :]\n",
    "                elif self.model_name == 'densenet' or 'efficientnet' in self.model_name:\n",
    "                    return torch.mean(my_embedding, (2, 3), True).numpy()[:, :, 0, 0]\n",
    "                else:\n",
    "                    return my_embedding.numpy()[:, :, 0, 0]\n",
    "        else:\n",
    "            image = self.normalize(self.to_tensor(self.scaler(img))).unsqueeze(0).to(self.device)\n",
    "\n",
    "            if self.model_name in ['alexnet', 'vgg']:\n",
    "                my_embedding = torch.zeros(1, self.layer_output_size)\n",
    "            elif self.model_name == 'densenet' or 'efficientnet' in self.model_name:\n",
    "                my_embedding = torch.zeros(1, self.layer_output_size, 7, 7)\n",
    "            else:\n",
    "                my_embedding = torch.zeros(1, self.layer_output_size, 1, 1)\n",
    "\n",
    "            def copy_data(m, i, o):\n",
    "                my_embedding.copy_(o.data)\n",
    "\n",
    "            h = self.extraction_layer.register_forward_hook(copy_data)\n",
    "            with torch.no_grad():\n",
    "                h_x = self.model(image)\n",
    "            h.remove()\n",
    "\n",
    "            if tensor:\n",
    "                return my_embedding\n",
    "            else:\n",
    "                if self.model_name in ['alexnet', 'vgg']:\n",
    "                    return my_embedding.numpy()[0, :]\n",
    "                elif self.model_name == 'densenet':\n",
    "                    return torch.mean(my_embedding, (2, 3), True).numpy()[0, :, 0, 0]\n",
    "                else:\n",
    "                    return my_embedding.numpy()[0, :, 0, 0]\n",
    "\n",
    "    # 주어진 모델 이름에 따라 모델과 해당 레이어 가져옴\n",
    "    def _get_model_and_layer(self, model_name, layer):\n",
    "        if model_name.startswith('resnet') and not model_name.startswith('resnet-'):\n",
    "            model = getattr(models, model_name)(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model._modules.get('avgpool')\n",
    "                self.layer_output_size = self.RESNET_OUTPUT_SIZES[model_name]\n",
    "            else:\n",
    "                layer = model._modules.get(layer)\n",
    "            return model, layer\n",
    "        elif model_name == 'resnet-18':\n",
    "            model = models.resnet18(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model._modules.get('avgpool')\n",
    "                self.layer_output_size = 512\n",
    "            else:\n",
    "                layer = model._modules.get(layer)\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        elif model_name == 'alexnet':\n",
    "            model = models.alexnet(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model.classifier[-2]\n",
    "                self.layer_output_size = 4096\n",
    "            else:\n",
    "                layer = model.classifier[-layer]\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        elif model_name == 'vgg':\n",
    "            model = models.vgg11_bn(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model.classifier[-2]\n",
    "                self.layer_output_size = model.classifier[-1].in_features\n",
    "            else:\n",
    "                layer = model.classifier[-layer]\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        elif model_name == 'densenet':\n",
    "            model = models.densenet121(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model.features[-1]\n",
    "                self.layer_output_size = model.classifier.in_features\n",
    "            else:\n",
    "                raise KeyError('Un support %s for layer parameters' % model_name)\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        elif \"efficientnet\" in model_name:\n",
    "            if model_name == \"efficientnet_b0\":\n",
    "                model = models.efficientnet_b0(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b1\":\n",
    "                model = models.efficientnet_b1(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b2\":\n",
    "                model = models.efficientnet_b2(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b3\":\n",
    "                model = models.efficientnet_b3(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b4\":\n",
    "                model = models.efficientnet_b4(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b5\":\n",
    "                model = models.efficientnet_b5(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b6\":\n",
    "                model = models.efficientnet_b6(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b7\":\n",
    "                model = models.efficientnet_b7(pretrained=True)\n",
    "            else:\n",
    "                raise KeyError('Un support %s.' % model_name)\n",
    "\n",
    "            if layer == 'default':\n",
    "                layer = model.features\n",
    "                self.layer_output_size = self.EFFICIENTNET_OUTPUT_SIZES[model_name]\n",
    "            else:\n",
    "                raise KeyError('Un support %s for layer parameters' % model_name)\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        else:\n",
    "            raise KeyError('Model %s was not found' % model_name)\n",
    "\n",
    "# 주어진 임베딩(벡터)간의 코사인 유사도 계산 - 두 벡터가 얼마나 유사한지 측정\n",
    "def calculate_similarity(embeddings):\n",
    "    return cosine_similarity(embeddings)\n",
    "\n",
    "# 주어진 임베딩(벡터)와 레이블 사용해 모델의 정확도 평가 - 유사도 임계값을 기준으로 올바르게 분류된 쌍의 비율을 계산\n",
    "def evaluate_model(embeddings, labels, thresholds):\n",
    "    results = []\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        class_similarities = defaultdict(list)\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for i in range(len(embeddings)):\n",
    "            for j in range(i + 1, len(embeddings)):\n",
    "                sim = cosine_similarity([embeddings[i]], [embeddings[j]])[0][0]\n",
    "                if labels[i] == labels[j]:\n",
    "                    class_similarities[labels[i]].append(sim)\n",
    "                    if sim > threshold:\n",
    "                        correct += 1\n",
    "                else:\n",
    "                    if sim <= threshold:\n",
    "                        correct += 1\n",
    "                total += 1\n",
    "\n",
    "        accuracy = correct / total\n",
    "        results.append((threshold, accuracy))\n",
    "    return results\n",
    "\n",
    "# 주어진 폴더에서 이미지 읽어오고, 이미지와 해당 레이블(폴더 이름) 반환\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    valid_image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']\n",
    "    for class_folder_name in os.listdir(folder):\n",
    "        class_folder_path = os.path.join(folder, class_folder_name)\n",
    "        if not os.path.isdir(class_folder_path):\n",
    "            continue\n",
    "        for filename in os.listdir(class_folder_path):\n",
    "            img_path = os.path.join(class_folder_path, filename)\n",
    "            if os.path.splitext(filename)[1].lower() in valid_image_extensions:\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "                images.append(img)\n",
    "                labels.append(class_folder_name)\n",
    "    return images, labels\n",
    "\n",
    "def plot_results(results, model_name):\n",
    "    thresholds = [r[0] for r in results]\n",
    "    accuracies = [r[1] for r in results]\n",
    "\n",
    "    plt.plot(thresholds, accuracies, marker='o', label=model_name)\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy vs. Threshold')\n",
    "    plt.grid(True)\n",
    "\n",
    "def classify_new_images(model_name, reference_folder, new_images_folder, thresholds, cuda=False):\n",
    "    # 기존 이미지와 레이블 불러오기\n",
    "    reference_images, reference_labels = load_images_from_folder(reference_folder)\n",
    "    \n",
    "    # 새로운 이미지와 레이블 불러오기\n",
    "    new_images, new_labels = load_images_from_folder(new_images_folder)\n",
    "    \n",
    "    # 모델 초기화\n",
    "    img2vec = Img2Vec(cuda=cuda, model=model_name)\n",
    "    \n",
    "    # 임베딩 추출\n",
    "    reference_embeddings = [img2vec.get_vec(img) for img in reference_images]\n",
    "    reference_embeddings = np.array(reference_embeddings)\n",
    "    \n",
    "    new_embeddings = [img2vec.get_vec(img) for img in new_images]\n",
    "    new_embeddings = np.array(new_embeddings)\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        correct_classifications = 0\n",
    "        incorrect_classifications = 0\n",
    "        \n",
    "        for i, new_embedding in enumerate(new_embeddings):\n",
    "            similarities = []\n",
    "            for j, ref_embedding in enumerate(reference_embeddings):\n",
    "                sim = cosine_similarity([new_embedding], [ref_embedding])[0][0]\n",
    "                if sim > threshold:\n",
    "                    similarities.append((sim, reference_labels[j]))\n",
    "\n",
    "            if similarities:\n",
    "                # 유사도 기준으로 정렬\n",
    "                similarities.sort(reverse=True, key=lambda x: x[0])\n",
    "                most_similar_label = similarities[0][1]\n",
    "            else:\n",
    "                most_similar_label = \"Unknown\"\n",
    "            \n",
    "            # 분류 결과 확인\n",
    "            if most_similar_label == new_labels[i]:\n",
    "                correct_classifications += 1\n",
    "            else:\n",
    "                incorrect_classifications += 1\n",
    "\n",
    "            print(f\"New Image {i+1}: Actual Label: {new_labels[i]}, Predicted Label: {most_similar_label}, Similarity: {similarities[0][0] if similarities else 'N/A'}\")\n",
    "        \n",
    "        # 정확도 계산\n",
    "        total_images = correct_classifications + incorrect_classifications\n",
    "        accuracy = correct_classifications / total_images if total_images > 0 else 0\n",
    "        \n",
    "        print(f\"\\nModel: {model_name}\")\n",
    "        print(f\"Threshold: {threshold}\")\n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "        print(f\"Correct Classifications: {correct_classifications}\")\n",
    "        print(f\"Incorrect Classifications: {incorrect_classifications}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    reference_folder = './data-gatter/train'\n",
    "    new_images_folder = './data-gatter/test'  # 새로운 이미지 폴더 경로\n",
    "    model_name = 'resnet18'\n",
    "    cuda = torch.cuda.is_available()\n",
    "    thresholds = np.arange(0.1, 1.0, 0.1)  # 다양한 임계값 설정\n",
    "\n",
    "    classify_new_images(model_name, reference_folder, new_images_folder, thresholds, cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. similarity threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import time\n",
    "from collections import Counter\n",
    "import certifi\n",
    "import os\n",
    "import ssl\n",
    "\n",
    "# SSL 인증서 설정\n",
    "os.environ['SSL_CERT_FILE'] = certifi.where()\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# 이미지를 벡터로 변환(임베딩)하는 역할 (이미지 ->> 벡터)\n",
    "class Img2Vec():\n",
    "    RESNET_OUTPUT_SIZES = {\n",
    "        'resnet18': 512,\n",
    "        'resnet34': 512,\n",
    "        'resnet50': 2048,\n",
    "        'resnet101': 2048,\n",
    "        'resnet152': 2048\n",
    "    }\n",
    "\n",
    "    EFFICIENTNET_OUTPUT_SIZES = {\n",
    "        'efficientnet_b0': 1280,\n",
    "        'efficientnet_b1': 1280,\n",
    "        'efficientnet_b2': 1408,\n",
    "        'efficientnet_b3': 1536,\n",
    "        'efficientnet_b4': 1792,\n",
    "        'efficientnet_b5': 2048,\n",
    "        'efficientnet_b6': 2304,\n",
    "        'efficientnet_b7': 2560\n",
    "    }\n",
    "\n",
    "    def __init__(self, cuda=False, model='resnet18', layer='default', layer_output_size=512, gpu=0):\n",
    "        self.device = torch.device(f\"cuda:{gpu}\" if cuda else \"cpu\")\n",
    "        self.layer_output_size = layer_output_size\n",
    "        self.model_name = model\n",
    "\n",
    "        self.model, self.extraction_layer = self._get_model_and_layer(model, layer)\n",
    "\n",
    "        self.model = self.model.to(self.device)\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "        self.scaler = transforms.Resize((224, 224))\n",
    "        self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                              std=[0.229, 0.224, 0.225])\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "\n",
    "    # 이미지를 입력으로 받아 벡터로 변환\n",
    "    def get_vec(self, img, tensor=False):\n",
    "        if type(img) == list:\n",
    "            a = [self.normalize(self.to_tensor(self.scaler(im))) for im in img]\n",
    "            images = torch.stack(a).to(self.device)\n",
    "            if self.model_name in ['alexnet', 'vgg']:\n",
    "                my_embedding = torch.zeros(len(img), self.layer_output_size)\n",
    "            elif self.model_name == 'densenet' or 'efficientnet' in self.model_name:\n",
    "                my_embedding = torch.zeros(len(img), self.layer_output_size, 7, 7)\n",
    "            else:\n",
    "                my_embedding = torch.zeros(len(img), self.layer_output_size, 1, 1)\n",
    "\n",
    "            def copy_data(m, i, o):\n",
    "                my_embedding.copy_(o.data)\n",
    "\n",
    "            h = self.extraction_layer.register_forward_hook(copy_data)\n",
    "            with torch.no_grad():\n",
    "                h_x = self.model(images)\n",
    "            h.remove()\n",
    "\n",
    "            if tensor:\n",
    "                return my_embedding\n",
    "            else:\n",
    "                if self.model_name in ['alexnet', 'vgg']:\n",
    "                    return my_embedding.numpy()[:, :]\n",
    "                elif self.model_name == 'densenet' or 'efficientnet' in self.model_name:\n",
    "                    return torch.mean(my_embedding, (2, 3), True).numpy()[:, :, 0, 0]\n",
    "                else:\n",
    "                    return my_embedding.numpy()[:, :, 0, 0]\n",
    "        else:\n",
    "            image = self.normalize(self.to_tensor(self.scaler(img))).unsqueeze(0).to(self.device)\n",
    "\n",
    "            if self.model_name in ['alexnet', 'vgg']:\n",
    "                my_embedding = torch.zeros(1, self.layer_output_size)\n",
    "            elif self.model_name == 'densenet' or 'efficientnet' in self.model_name:\n",
    "                my_embedding = torch.zeros(1, self.layer_output_size, 7, 7)\n",
    "            else:\n",
    "                my_embedding = torch.zeros(1, self.layer_output_size, 1, 1)\n",
    "\n",
    "            def copy_data(m, i, o):\n",
    "                my_embedding.copy_(o.data)\n",
    "\n",
    "            h = self.extraction_layer.register_forward_hook(copy_data)\n",
    "            with torch.no_grad():\n",
    "                h_x = self.model(image)\n",
    "            h.remove()\n",
    "\n",
    "            if tensor:\n",
    "                return my_embedding\n",
    "            else:\n",
    "                if self.model_name in ['alexnet', 'vgg']:\n",
    "                    return my_embedding.numpy()[0, :]\n",
    "                elif self.model_name == 'densenet':\n",
    "                    return torch.mean(my_embedding, (2, 3), True).numpy()[0, :, 0, 0]\n",
    "                else:\n",
    "                    return my_embedding.numpy()[0, :, 0, 0]\n",
    "\n",
    "    # 주어진 모델 이름에 따라 모델과 해당 레이어 가져옴\n",
    "    def _get_model_and_layer(self, model_name, layer):\n",
    "        if model_name.startswith('resnet') and not model_name.startswith('resnet-'):\n",
    "            model = getattr(models, model_name)(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model._modules.get('avgpool')\n",
    "                self.layer_output_size = self.RESNET_OUTPUT_SIZES[model_name]\n",
    "            else:\n",
    "                layer = model._modules.get(layer)\n",
    "            return model, layer\n",
    "        elif model_name == 'resnet-18':\n",
    "            model = models.resnet18(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model._modules.get('avgpool')\n",
    "                self.layer_output_size = 512\n",
    "            else:\n",
    "                layer = model._modules.get(layer)\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        elif model_name == 'alexnet':\n",
    "            model = models.alexnet(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model.classifier[-2]\n",
    "                self.layer_output_size = 4096\n",
    "            else:\n",
    "                layer = model.classifier[-layer]\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        elif model_name == 'vgg':\n",
    "            model = models.vgg11_bn(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model.classifier[-2]\n",
    "                self.layer_output_size = model.classifier[-1].in_features\n",
    "            else:\n",
    "                layer = model.classifier[-layer]\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        elif model_name == 'densenet':\n",
    "            model = models.densenet121(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model.features[-1]\n",
    "                self.layer_output_size = model.classifier.in_features\n",
    "            else:\n",
    "                raise KeyError('Un support %s for layer parameters' % model_name)\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        elif \"efficientnet\" in model_name:\n",
    "            if model_name == \"efficientnet_b0\":\n",
    "                model = models.efficientnet_b0(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b1\":\n",
    "                model = models.efficientnet_b1(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b2\":\n",
    "                model = models.efficientnet_b2(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b3\":\n",
    "                model = models.efficientnet_b3(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b4\":\n",
    "                model = models.efficientnet_b4(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b5\":\n",
    "                model = models.efficientnet_b5(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b6\":\n",
    "                model = models.efficientnet_b6(pretrained=True)\n",
    "            elif model_name == \"efficientnet_b7\":\n",
    "                model = models.efficientnet_b7(pretrained=True)\n",
    "            else:\n",
    "                raise KeyError('Un support %s.' % model_name)\n",
    "\n",
    "            if layer == 'default':\n",
    "                layer = model.features\n",
    "                self.layer_output_size = self.EFFICIENTNET_OUTPUT_SIZES[model_name]\n",
    "            else:\n",
    "                raise KeyError('Un support %s for layer parameters' % model_name)\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        else:\n",
    "            raise KeyError('Model %s was not found' % model_name)\n",
    "\n",
    "def calculate_similarity(embeddings):\n",
    "    return cosine_similarity(embeddings)\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    valid_image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']\n",
    "    for class_folder_name in os.listdir(folder):\n",
    "        class_folder_path = os.path.join(folder, class_folder_name)\n",
    "        if not os.path.isdir(class_folder_path):\n",
    "            continue\n",
    "        for filename in os.listdir(class_folder_path):\n",
    "            img_path = os.path.join(class_folder_path, filename)\n",
    "            if os.path.splitext(filename)[1].lower() in valid_image_extensions:\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "                images.append(img)\n",
    "                labels.append(class_folder_name)\n",
    "    return images, labels\n",
    "\n",
    "def classify_images(model_names, folder_path, cuda=False):\n",
    "    images, labels = load_images_from_folder(folder_path)\n",
    "    results = {}\n",
    "\n",
    "    for model_name in model_names:\n",
    "        print(f\"Evaluating model {model_name}\")\n",
    "        img2vec = Img2Vec(cuda=cuda, model=model_name)\n",
    "        start_time = time.time()\n",
    "        embeddings = [img2vec.get_vec(img) for img in images]\n",
    "        embeddings = np.array(embeddings)\n",
    "        processing_time = (time.time() - start_time) / len(images)\n",
    "\n",
    "        correct_classifications = 0\n",
    "        incorrect_classifications = 0\n",
    "\n",
    "        thresholds = np.linspace(0, 1, 101)  # 0부터 1까지 101개의 임계값\n",
    "\n",
    "        best_threshold = 0\n",
    "        best_accuracy = 0\n",
    "\n",
    "        for threshold in thresholds:\n",
    "            correct_classifications = 0\n",
    "            incorrect_classifications = 0\n",
    "\n",
    "            for i, embedding in enumerate(embeddings):\n",
    "                similarities = []\n",
    "                for j in range(len(images)):\n",
    "                    if i != j:\n",
    "                        sim = cosine_similarity([embedding], [embeddings[j]])[0][0]\n",
    "                        if sim >= threshold:\n",
    "                            similarities.append((sim, labels[j]))\n",
    "\n",
    "                if similarities:\n",
    "                    similarities.sort(reverse=True, key=lambda x: x[0])\n",
    "                    most_similar_label = similarities[0][1]\n",
    "\n",
    "                    if most_similar_label == labels[i]:\n",
    "                        correct_classifications += 1\n",
    "                    else:\n",
    "                        incorrect_classifications += 1\n",
    "\n",
    "            total_images = correct_classifications + incorrect_classifications\n",
    "            accuracy = correct_classifications / total_images\n",
    "\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_threshold = threshold\n",
    "\n",
    "        results[model_name] = {\n",
    "            'best_threshold': best_threshold,\n",
    "            'accuracy': best_accuracy,\n",
    "            'correct_classifications': correct_classifications,\n",
    "            'incorrect_classifications': incorrect_classifications,\n",
    "            'processing_time': processing_time\n",
    "        }\n",
    "\n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    folder_path = './data-gatter/train'\n",
    "    model_names = ['resnet18', 'resnet50', 'efficientnet_b0', 'efficientnet_b7']\n",
    "    cuda = torch.cuda.is_available()\n",
    "\n",
    "    results = classify_images(model_names, folder_path, cuda)\n",
    "    for model_name, result in results.items():\n",
    "        print(f\"\\nModel: {model_name}\")\n",
    "        print(f\"Best Threshold: {result['best_threshold']}\")\n",
    "        print(f\"Accuracy: {result['accuracy']}\")\n",
    "        print(f\"Correct Classifications: {result['correct_classifications']}\")\n",
    "        print(f\"Incorrect Classifications: {result['incorrect_classifications']}\")\n",
    "        print(f\"Processing Time per Image: {result['processing_time']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
