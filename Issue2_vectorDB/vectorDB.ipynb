{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. vector database 선택 및 설정\n",
    "### 1) Pinecone\n",
    "### 2) Chroma \n",
    "### 3) Weaviate \n",
    "### 4) Qdrant\n",
    "### 5) Faiss\n",
    "### 6) Milvus\n",
    "\n",
    "https://meetcody.ai/ko/blog/2024%EB%85%84%EC%97%90-%EC%8B%9C%EB%8F%84%ED%95%B4-%EB%B3%BC-%EB%A7%8C%ED%95%9C-%EC%83%81%EC%9C%84-5%EA%B0%80%EC%A7%80-%EB%B2%A1%ED%84%B0-%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B2%A0%EC%9D%B4%EC%8A%A4/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PostgreSQL Docker 이미지 실행\n",
    "```terminal\n",
    "docker run --name my_postgres -e POSTGRES_PASSWORD=aiv11011 -d -p 5432:5432 postgres\n",
    "```\n",
    "\n",
    "# 가상환경 생성, 활성화\n",
    "\n",
    "```terminal\n",
    " python -m venv venv\n",
    " source venv/bin/activate\n",
    "```\n",
    "\n",
    "# 가상 환경 활성화된 상태에서 필요한 패키지 설치\n",
    "```terminal\n",
    "pip install psycopg2-binary sqlalchemy torch torchvision pillow numpy\n",
    "```\n",
    "\n",
    "# PostgreSQL 셸에서 데이터 확인\n",
    "# 1. PostgreSQL 셸 접속\n",
    "# 2. 데이터베이스 ㅡ사용\n",
    "# 3. 데이터 조회\n",
    "```terminal\n",
    "docker exec -it my_postgres psql -U postgres\n",
    "\\c postgres\n",
    "SELECT * FROM image_embeddings;\n",
    "```\n",
    "\n",
    "# 테이블 삭제\n",
    "```terminal\n",
    "DROP TABLE IF EXISTS image_embeddings;\n",
    "```\n",
    "\n",
    "# 테이블 다시 생성\n",
    "```terminal\n",
    "CREATE TABLE image_embeddings (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    image_path VARCHAR(255) UNIQUE NOT NULL,\n",
    "    label VARCHAR(255) NOT NULL,\n",
    "    embedding FLOAT[] NOT NULL\n",
    ");\n",
    "```\n",
    "### Milvus 설치 및 설정 \n",
    "\n",
    "# 1. Milvus 실행 위해 `docker-compose.yml` 파일 작성\n",
    "#    해당 파일 있는 디렉토리에서 다음 명령어 실행 -> Milvus 시행\n",
    "```terminal\n",
    "docker-compose up -d\n",
    "```\n",
    "\n",
    "# 2. PyMilvus 설치\n",
    "#    Milvus와 상호작용하기 위해 Python 클라이언트 라이브러리인 `pymilvus` 설치\n",
    "```terminal\n",
    "pip install pymilvus\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 설치 스크립트 다운로드\n",
    "```terminal\n",
    "curl -sfL https://raw.githubusercontent.com/milvus-io/milvus/master/scripts/standalone_embed.sh -o standalone_embed.sh\n",
    "```\n",
    "\n",
    "# 스크립트 실행 권한 부여\n",
    "```terminal\n",
    "chmod +x standalone_embed.sh\n",
    "```\n",
    "\n",
    "# Docker 컨테이너 시작\n",
    "```terminal\n",
    "bash standalone_embed.sh start\n",
    "```\n",
    "\n",
    "# Milvus 컨테이너 상태 확인 - 컨테이너가 정상적으로 실행 중인지 확인하려면 다음 명령어를 사용합니다.\n",
    "```terminal\n",
    "docker ps\n",
    "```\n",
    "#   실행 중인 컨테이너 목록에 milvus-standalone 컨테이너가 표시, STATUS가 healthy로 표시되면 정상적으로 실행된 것\n",
    "\n",
    "\n",
    "# 의존성 install\n",
    "```terminal\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "```terminal\n",
    "docker run -d --name weaviate --env QUERY_DEFAULTS_LIMIT=25 --env CLUSTERS_PEERS_ACTION_BATCHING_WORKERS=4 --env CLUSTER_SLAVES_COUNT=2 --env AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED=true --restart=unless-stopped --env PERSISTENCE_DATA_PATH=\"/var/lib/weaviate\" --volume /var/lib/weaviate:/var/lib/weaviate --publish 8080:8080 semitechnologies/weaviate:1.19.2\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pinecone - ConvNeXT, RegNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ssl\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from open_clip import create_model_and_transforms\n",
    "from torchvision import transforms, models\n",
    "\n",
    "# SSL 인증서 설정\n",
    "import certifi\n",
    "os.environ['SSL_CERT_FILE'] = certifi.where()\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "class CoCaImg2Vec():\n",
    "    def __init__(self, model_name, pretrained, cuda=False):\n",
    "        self.model, _, self.transform = create_model_and_transforms(model_name, pretrained=pretrained)\n",
    "        self.device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "        self.model = self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "    def get_vec(self, img):\n",
    "        image = self.transform(img).unsqueeze(0).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            embedding = self.model.encode_image(image).cpu().numpy().flatten()\n",
    "        return embedding\n",
    "\n",
    "class Img2Vec():\n",
    "    def __init__(self, model_name, cuda=False):\n",
    "        self.device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "        self.model = getattr(models, model_name)(pretrained=True).to(self.device)\n",
    "        self.model.eval()\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def get_vec(self, img):\n",
    "        image = self.transform(img).unsqueeze(0).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            embedding = self.model(image)\n",
    "        embedding_np = embedding.cpu().numpy().flatten()\n",
    "        #print(f\"Embedding dimension for {self.model.__class__.__name__}: {embedding_np.shape[0]}\")\n",
    "        return embedding_np\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    valid_image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']\n",
    "    for class_folder_name in os.listdir(folder):\n",
    "        class_folder_path = os.path.join(folder, class_folder_name)\n",
    "        if not os.path.isdir(class_folder_path):\n",
    "            continue\n",
    "        for filename in os.listdir(class_folder_path):\n",
    "            img_path = os.path.join(class_folder_path, filename)\n",
    "            if os.path.splitext(filename)[1].lower() in valid_image_extensions:\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "                images.append(img)\n",
    "                labels.append(class_folder_name)\n",
    "    return images, labels\n",
    "\n",
    "def create_pinecone_index(api_key, index_name, dimension):\n",
    "    pc = Pinecone(api_key=api_key)\n",
    "    if index_name not in pc.list_indexes().names():\n",
    "        pc.create_index(\n",
    "            name=index_name,\n",
    "            dimension=dimension,\n",
    "            metric='cosine',\n",
    "            spec=ServerlessSpec(\n",
    "                cloud='aws',\n",
    "                region=\"us-east-1\"\n",
    "            )\n",
    "        )\n",
    "    return pc.Index(index_name)\n",
    "\n",
    "def save_embeddings_to_pinecone(index, embeddings, labels, namespace):\n",
    "    vectors = []\n",
    "    for i, emb in enumerate(embeddings):\n",
    "        vectors.append({\n",
    "            \"id\": f\"vec{i+1}\",\n",
    "            \"values\": emb.tolist(),\n",
    "            \"metadata\": {\"label\": labels[i]}\n",
    "        })\n",
    "\n",
    "    index.upsert(\n",
    "        vectors=vectors,\n",
    "        namespace=namespace\n",
    "    )\n",
    "    \n",
    "    return vectors\n",
    "\n",
    "def classify_images_with_pinecone(model_dict, folder_path, api_key, index_name, namespace, cuda=False):\n",
    "    images, labels = load_images_from_folder(folder_path)\n",
    "    all_vectors = []\n",
    "\n",
    "    for model_name, model in model_dict.items():\n",
    "        print(f\"Evaluating model {model_name}\")\n",
    "        img2vec = Img2Vec(model, cuda=cuda)\n",
    "        if img2vec.model is None:\n",
    "            continue\n",
    "\n",
    "        start_time = time.time()\n",
    "        embeddings = [img2vec.get_vec(img) for img in images]\n",
    "        embeddings = [e for e in embeddings if e is not None]\n",
    "        embeddings = np.array(embeddings)\n",
    "        processing_time = (time.time() - start_time) / len(images)\n",
    "        print(f\"Processing Time per Image: {processing_time}\")\n",
    "\n",
    "        # Create Pinecone index\n",
    "        index = create_pinecone_index(api_key, index_name, embeddings.shape[1])\n",
    "        \n",
    "        # Save embeddings to Pinecone\n",
    "        vectors = save_embeddings_to_pinecone(index, embeddings, labels, namespace)\n",
    "        all_vectors.extend(vectors)\n",
    "\n",
    "    return all_vectors\n",
    "\n",
    "def visualize_embeddings(vectors):\n",
    "    print(\"Embedding vectors and their metadata:\")\n",
    "    for vector in vectors:\n",
    "        print(f\"ID: {vector['id']}, Label: {vector['metadata']['label']}, Vector: {vector['values'][:5]}...\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    folder_path = './data-gatter/train'\n",
    "    api_key = 'f5001027-9bd4-4abb-8dd6-a2db16540ecc'\n",
    "    index_name = 'quickstart'\n",
    "    namespace = 'ns1'\n",
    "    \n",
    "    model_dict = {\n",
    "        'ConvNeXt': 'convnext_base',\n",
    "        'RegNet': 'regnet_y_16gf',\n",
    "    }\n",
    "\n",
    "    cuda = torch.cuda.is_available()\n",
    "\n",
    "    vectors = classify_images_with_pinecone(model_dict, folder_path, api_key, index_name, namespace, cuda)\n",
    "    visualize_embeddings(vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docker를 사용하여 PostgreSQL 데이터베이스와 pgvector 확장을 설정하고, Python 스크립트를 실행하는 방법\n",
    "\n",
    "# 1. Dockerfile 작성 \n",
    "#    필요한 Python 환경 설정, 스크립트 실행하도록\n",
    "#    requirements.txt 작성\n",
    "\n",
    "\n",
    "# 2. docker-compose.yml 작성\n",
    "#    PostgreSQL DB와 애플리케이션 동시에 실행할 수 있도록\n",
    "\n",
    "# 3. PostgreSQL에 pgvector 확장 설치\n",
    "#    pgvector 확장 설치 위해 PostgreSQL 컨테이너 시작된 후 초기화 스크립트를 실행하도록 설정.\n",
    "\n",
    "# 4. 디렉토리 구조\n",
    "```terminal\n",
    "Issue2_vectorDB/\n",
    "├── docker-compose.yml\n",
    "├── Dockerfile\n",
    "├── init-db.sh\n",
    "├── Img2Vec.py\n",
    "├── ImageEmbedding.py\n",
    "├── postgresStore.py\n",
    "├── postgresFind.py\n",
    "└── requirements.txt\n",
    "\n",
    "```\n",
    "\n",
    "# 5. Docker Compose 실행\n",
    "#    PostgreSQL DB와 애플리케이션 컨테이너 빌드하고 시작\n",
    "#    PostgreSQL 컨테이너 - pgvector 확장 설치\n",
    "#    애플리케이션 컨테이너 - `postgresStore.py` 스크립트 실행하여 이미지 임베딩 DB에 저장\n",
    "```terminal\n",
    "docker-compose up --build\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# PostgreSQL 셸에서 데이터 확인\n",
    "# 1. PostgreSQL 셸 접속\n",
    "# 2. 데이터베이스 ㅡ사용\n",
    "# 3. 데이터 조회\n",
    "```terminal\n",
    "docker exec -it my_postgres psql -U postgres\n",
    "\\c postgres\n",
    "SELECT * FROM image_embeddings;\n",
    "```\n",
    "\n",
    "# 테이블 삭제\n",
    "```terminal\n",
    "DROP TABLE IF EXISTS image_embeddings;\n",
    "```\n",
    "\n",
    "# 테이블 다시 생성\n",
    "```terminal\n",
    "CREATE TABLE image_embeddings (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    image_path VARCHAR(255) UNIQUE NOT NULL,\n",
    "    label VARCHAR(255) NOT NULL,\n",
    "    embedding FLOAT[] NOT NULL\n",
    ");\n",
    "```\n",
    "### Milvus 설치 및 설정 \n",
    "\n",
    "# 1. Milvus 실행 위해 `docker-compose.yml` 파일 작성\n",
    "#    해당 파일 있는 디렉토리에서 다음 명령어 실행 -> Milvus 시행\n",
    "```terminal\n",
    "docker-compose up -d\n",
    "```\n",
    "\n",
    "# 2. PyMilvus 설치\n",
    "#    Milvus와 상호작용하기 위해 Python 클라이언트 라이브러리인 `pymilvus` 설치\n",
    "```terminal\n",
    "pip install pymilvus\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 설치 스크립트 다운로드\n",
    "```terminal\n",
    "curl -sfL https://raw.githubusercontent.com/milvus-io/milvus/master/scripts/standalone_embed.sh -o standalone_embed.sh\n",
    "```\n",
    "\n",
    "# 스크립트 실행 권한 부여\n",
    "```terminal\n",
    "chmod +x standalone_embed.sh\n",
    "```\n",
    "\n",
    "# Docker 컨테이너 시작\n",
    "```terminal\n",
    "bash standalone_embed.sh start\n",
    "```\n",
    "\n",
    "# Milvus 컨테이너 상태 확인 - 컨테이너가 정상적으로 실행 중인지 확인하려면 다음 명령어를 사용합니다.\n",
    "```terminal\n",
    "docker ps\n",
    "```\n",
    "#   실행 중인 컨테이너 목록에 milvus-standalone 컨테이너가 표시, STATUS가 healthy로 표시되면 정상적으로 실행된 것\n",
    "\n",
    "\n",
    "# 의존성 install\n",
    "```terminal\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "```terminal\n",
    "docker run -d --name weaviate --env QUERY_DEFAULTS_LIMIT=25 --env CLUSTERS_PEERS_ACTION_BATCHING_WORKERS=4 --env CLUSTER_SLAVES_COUNT=2 --env AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED=true --restart=unless-stopped --env PERSISTENCE_DATA_PATH=\"/var/lib/weaviate\" --volume /var/lib/weaviate:/var/lib/weaviate --publish 8080:8080 semitechnologies/weaviate:1.19.2\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
